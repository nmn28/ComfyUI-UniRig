<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ComfyUI-UniRig - Test Results</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #1a1a2e;
            color: #eee;
            min-height: 100vh;
            line-height: 1.5;
        }

        header {
            background: #16213e;
            padding: 1.5rem 2rem;
            border-bottom: 1px solid #0f3460;
        }

        h1 {
            font-size: 1.5rem;
            margin-bottom: 0.25rem;
        }

        h1 a {
            color: #fff;
            text-decoration: none;
        }

        h1 a:hover { color: #4da6ff; }

        .meta {
            color: #888;
            font-size: 0.9rem;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 1.5rem;
        }

        /* Summary Section */
        .summary {
            background: #16213e;
            border-radius: 8px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
        }

        .progress-bar {
            background: #0f3460;
            border-radius: 4px;
            height: 24px;
            overflow: hidden;
            margin-bottom: 1rem;
        }

        .progress-fill {
            background: linear-gradient(90deg, #00c853, #69f0ae);
            height: 100%;
            transition: width 0.3s ease;
        }

        .progress-fill.has-failures {
            background: linear-gradient(90deg, #00c853 0%, #00c853 80.0%, #ff5252 80.0%, #ff5252 100%);
            width: 100% !important;
        }

        .stats {
            display: flex;
            gap: 1rem;
            flex-wrap: wrap;
            align-items: center;
        }

        .stat-badge {
            padding: 0.5rem 1rem;
            border-radius: 4px;
            font-weight: 600;
            font-size: 0.9rem;
        }

        .stat-pass {
            background: rgba(0, 200, 83, 0.2);
            color: #69f0ae;
        }

        .stat-fail {
            background: rgba(255, 82, 82, 0.2);
            color: #ff8a80;
        }

        .stat-total {
            color: #888;
            font-size: 1rem;
        }

        /* Failed Section */
        .failed-section {
            background: rgba(255, 82, 82, 0.1);
            border: 1px solid rgba(255, 82, 82, 0.3);
            border-radius: 8px;
            padding: 1rem;
            margin-bottom: 1.5rem;
        }

        .failed-section h2 {
            color: #ff8a80;
            font-size: 1rem;
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .failed-item {
            background: #16213e;
            border-radius: 6px;
            padding: 1rem;
            margin-bottom: 0.5rem;
        }

        .failed-item:last-child {
            margin-bottom: 0;
        }

        .failed-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.5rem;
        }

        .failed-name {
            font-weight: 600;
            color: #ff8a80;
        }

        .failed-duration {
            color: #888;
            font-size: 0.85rem;
        }

        .failed-error {
            background: #0f3460;
            padding: 0.75rem;
            border-radius: 4px;
            font-family: monospace;
            font-size: 0.85rem;
            color: #ffa;
            margin-bottom: 0.5rem;
        }

        .log-link {
            color: #4da6ff;
            text-decoration: none;
            font-size: 0.85rem;
        }

        .log-link:hover {
            text-decoration: underline;
        }

        /* Workflow Grid */
        .section-title {
            font-size: 1rem;
            color: #888;
            margin-bottom: 1rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .workflow-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
            gap: 1rem;
        }

        .workflow-card {
            background: #16213e;
            border-radius: 8px;
            overflow: hidden;
            transition: transform 0.2s, box-shadow 0.2s;
        }

        .workflow-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.3);
        }

        .workflow-card.clickable {
            cursor: pointer;
        }

        .workflow-card.failed {
            border: 2px solid #ff5252;
            box-shadow: 0 0 8px rgba(255, 82, 82, 0.3);
        }

        .workflow-screenshot {
            width: 100%;
            aspect-ratio: 16/10;
            object-fit: cover;
            background: #0f3460;
            display: block;
        }

        .workflow-screenshot.placeholder {
            display: flex;
            align-items: center;
            justify-content: center;
            color: #444;
            font-size: 0.85rem;
        }

        .workflow-info {
            padding: 0.75rem 1rem;
            border-top: 1px solid #0f3460;
        }

        .workflow-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.25rem;
        }

        .workflow-name {
            font-weight: 500;
            font-size: 0.9rem;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
            max-width: 60%;
        }

        .workflow-badge {
            padding: 0.2rem 0.5rem;
            border-radius: 3px;
            font-size: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
        }

        .workflow-badge.pass {
            background: rgba(0, 200, 83, 0.2);
            color: #69f0ae;
        }

        .workflow-badge.fail {
            background: rgba(255, 82, 82, 0.2);
            color: #ff8a80;
        }

        .workflow-meta {
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 0.8rem;
            color: #666;
        }

        /* Lightbox */
        .lightbox {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0,0,0,0.95);
            z-index: 1000;
            justify-content: center;
            align-items: flex-start;
            padding: 2rem;
            overflow-y: auto;
        }

        .lightbox.active {
            display: flex;
        }

        .lightbox-content {
            display: flex;
            flex-direction: column;
            max-width: 1200px;
            width: 100%;
            margin: auto;
        }

        .lightbox-content img {
            max-width: 100%;
            max-height: 60vh;
            object-fit: contain;
            border-radius: 4px;
            align-self: center;
        }

        .lightbox-close {
            position: fixed;
            top: 1rem;
            right: 1.5rem;
            font-size: 2rem;
            color: #fff;
            cursor: pointer;
            opacity: 0.7;
            background: none;
            border: none;
            z-index: 1001;
        }

        .lightbox-close:hover {
            opacity: 1;
        }

        .lightbox-info {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem;
            background: #16213e;
            border-radius: 4px;
            margin-top: 1rem;
        }

        .lightbox-title {
            font-size: 1.1rem;
            font-weight: 600;
            color: #fff;
        }

        .lightbox-hardware {
            display: block;
            font-size: 0.8rem;
            color: #888;
            margin-top: 0.25rem;
        }

        .lightbox-meta {
            display: flex;
            gap: 1rem;
            align-items: center;
        }

        .lightbox-badge {
            padding: 0.25rem 0.75rem;
            border-radius: 4px;
            font-size: 0.85rem;
            font-weight: 600;
            text-transform: uppercase;
        }

        .lightbox-badge.pass {
            background: rgba(0, 200, 83, 0.2);
            color: #69f0ae;
        }

        .lightbox-badge.fail {
            background: rgba(255, 82, 82, 0.2);
            color: #ff8a80;
        }

        .lightbox-duration {
            color: #888;
            font-size: 0.9rem;
        }

        .lightbox-log {
            background: #0f3460;
            border-radius: 4px;
            padding: 1rem;
            margin-top: 1rem;
            max-height: 300px;
            overflow-y: auto;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 0.8rem;
            line-height: 1.4;
            white-space: pre-wrap;
            word-break: break-all;
            color: #ccc;
        }

        .lightbox-log::-webkit-scrollbar {
            width: 8px;
        }

        .lightbox-log::-webkit-scrollbar-track {
            background: #16213e;
            border-radius: 4px;
        }

        .lightbox-log::-webkit-scrollbar-thumb {
            background: #4da6ff;
            border-radius: 4px;
        }

        /* Video Player */
        .video-player {
            display: none;
            margin-top: 1rem;
            background: #1a1a2e;
            border-radius: 8px;
            padding: 1rem;
        }

        .video-player.active {
            display: block;
        }

        .video-controls {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin-top: 0.5rem;
        }

        .video-play-btn {
            background: #4da6ff;
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
        }

        .video-play-btn:hover {
            background: #3d8ee0;
        }

        .video-frame-counter {
            color: #888;
            font-size: 0.85rem;
        }

        .video-slider-container {
            padding: 15px 0;
        }

        /* noUiSlider customization */
        #video-slider {
            height: 6px;
            background: #333;
            border: none;
            box-shadow: none;
        }

        #video-slider .noUi-connect {
            background: #4da6ff;
        }

        #video-slider .noUi-handle {
            width: 16px;
            height: 16px;
            background: #4da6ff;
            border: none;
            border-radius: 50%;
            box-shadow: none;
            top: -5px;
            right: -8px;
            cursor: pointer;
        }

        #video-slider .noUi-handle:before,
        #video-slider .noUi-handle:after {
            display: none;
        }

        /* Pips (tick marks) */
        .noUi-pips {
            color: #666;
        }

        .noUi-marker {
            background: #4da6ff;
            width: 2px;
        }

        .noUi-marker-large {
            height: 12px;
        }

        .noUi-value {
            display: none;
        }

        /* Footer */
        footer {
            text-align: center;
            padding: 2rem;
            color: #666;
            font-size: 0.85rem;
        }

        footer a {
            color: #4da6ff;
            text-decoration: none;
        }

        footer a:hover {
            text-decoration: underline;
        }

        /* Responsive */
        @media (max-width: 600px) {
            .workflow-grid {
                grid-template-columns: 1fr;
            }

            .stats {
                flex-direction: column;
                align-items: flex-start;
            }
        }
    </style>
    <link href="https://cdn.jsdelivr.net/npm/nouislider@15/dist/nouislider.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/nouislider@15/dist/nouislider.min.js"></script>
</head>
<body>
    <header>
        <h1><a href="https://github.com/PozzettiAndrea/ComfyUI-UniRig">ComfyUI-UniRig</a> Test Results</h1>
        <p class="meta">2026-01-25 01:17 UTC</p>
    </header>

    <div class="container">
        <div class="summary">
            <div class="progress-bar">
                <div class="progress-fill has-failures" style="width: 80.0%"></div>
            </div>
            <div class="stats">
                <span class="stat-badge stat-pass">4 PASSED</span>
                <span class="stat-badge stat-fail">1 FAILED</span>
                <span class="stat-total">4/5 tests (80.0%)</span>
            </div>
        </div>

        
        <div class="failed-section">
            <h2>Failed Tests</h2>
            
            <div class="failed-item">
                <div class="failed-header">
                    <span class="failed-name">apply_animation</span>
                    <span class="failed-duration">5.81s</span>
                </div>
                <div class="failed-error">Workflow validation failed

Details:
Prompt outputs failed validation
Node errors:
{
  &quot;8&quot;: {
    &quot;errors&quot;: [
      {
        &quot;type&quot;: &quot;required_input_missing&quot;,
        &quot;message&quot;: &quot;Required input is missing&quot;,
        &quot;details&quot;: &quot;fbx_file&quot;,
        &quot;extra_info&quot;: {
          &quot;input_name&quot;: &quot;fbx_file&quot;
        }
      }
    ],
    &quot;dependent_outputs&quot;: [
      &quot;7&quot;,
      &quot;6&quot;
    ],
    &quot;class_type&quot;: &quot;UniRigLoadRiggedMesh&quot;
  }
}</div>
            </div>
        
        </div>
    

        <h2 class="section-title">All Workflows</h2>
        <div class="workflow-grid">
            
            <div class="workflow-card clickable failed" onclick="openLightboxByName('apply_animation')">
                <div class="workflow-screenshot placeholder">No screenshot</div>
                <div class="workflow-info">
                    <div class="workflow-header">
                        <span class="workflow-name" title="apply_animation">apply_animation</span>
                        <span class="workflow-badge fail">fail</span>
                    </div>
                    <div class="workflow-meta">
                        <span>5.81s</span>
                    </div>
                </div>
            </div>
        

            <div class="workflow-card clickable " onclick="openLightboxByName('rig_human_with_texture')">
                
                <img class="workflow-screenshot" src="screenshots/rig_human_with_texture_executed.png"
                     alt="rig_human_with_texture" loading="lazy">
            
                <div class="workflow-info">
                    <div class="workflow-header">
                        <span class="workflow-name" title="rig_human_with_texture">rig_human_with_texture</span>
                        <span class="workflow-badge pass">pass</span>
                    </div>
                    <div class="workflow-meta">
                        <span>72.02s</span>
                    </div>
                </div>
            </div>
        

            <div class="workflow-card clickable " onclick="openLightboxByName('rig_human_with_texture_mia')">
                
                <img class="workflow-screenshot" src="screenshots/rig_human_with_texture_mia_executed.png"
                     alt="rig_human_with_texture_mia" loading="lazy">
            
                <div class="workflow-info">
                    <div class="workflow-header">
                        <span class="workflow-name" title="rig_human_with_texture_mia">rig_human_with_texture_mia</span>
                        <span class="workflow-badge pass">pass</span>
                    </div>
                    <div class="workflow-meta">
                        <span>194.69s</span>
                    </div>
                </div>
            </div>
        

            <div class="workflow-card clickable " onclick="openLightboxByName('rig_human_with_texture_mia_debug')">
                
                <img class="workflow-screenshot" src="screenshots/rig_human_with_texture_mia_debug_executed.png"
                     alt="rig_human_with_texture_mia_debug" loading="lazy">
            
                <div class="workflow-info">
                    <div class="workflow-header">
                        <span class="workflow-name" title="rig_human_with_texture_mia_debug">rig_human_with_texture_mia_debug</span>
                        <span class="workflow-badge pass">pass</span>
                    </div>
                    <div class="workflow-meta">
                        <span>15.62s</span>
                    </div>
                </div>
            </div>
        

            <div class="workflow-card clickable " onclick="openLightboxByName('rigged_manipulator')">
                
                <img class="workflow-screenshot" src="screenshots/rigged_manipulator_executed.png"
                     alt="rigged_manipulator" loading="lazy">
            
                <div class="workflow-info">
                    <div class="workflow-header">
                        <span class="workflow-name" title="rigged_manipulator">rigged_manipulator</span>
                        <span class="workflow-badge pass">pass</span>
                    </div>
                    <div class="workflow-meta">
                        <span>33.04s</span>
                    </div>
                </div>
            </div>
        
        </div>
    </div>

    <div class="lightbox" id="lightbox">
        <button class="lightbox-close" onclick="closeLightbox()">&times;</button>
        <div class="lightbox-content">
            <img id="lightbox-img" src="" alt="">
            <div class="video-player" id="video-player">
                <div class="video-slider-container">
                    <div id="video-slider"></div>
                </div>
                <div class="video-controls">
                    <span class="video-frame-counter" id="video-frame-counter">0.0s / 0.0s</span>
                </div>
            </div>
            <div class="lightbox-info">
                <div>
                    <span class="lightbox-title" id="lightbox-title"></span>
                    <span class="lightbox-hardware" id="lightbox-hardware"></span>
                </div>
                <div class="lightbox-meta">
                    <span class="lightbox-badge" id="lightbox-badge"></span>
                    <span class="lightbox-duration" id="lightbox-duration"></span>
                </div>
            </div>
            <pre class="lightbox-log" id="lightbox-log"></pre>
        </div>
    </div>

    <footer>
        Generated by <a href="https://github.com/PozzettiAndrea/comfy-test">comfy-test</a>
    </footer>

    <script>
        // Store workflow data for hash-based linking
        const workflowData = {"apply_animation": {"src": "", "title": "apply_animation", "status": "fail", "duration": "5.81", "log": "Capturing execution frames: apply_animation.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 3 nodes\n  [ComfyUI]   Node 6: UniRigApplyAnimation\n  [ComfyUI]     Inputs: {\"model_fbx_path\": [\"8\", 0], \"animation_type\": \"mixamo\", \"animation_file\": \"Breakdance.fbx\", \"output_name\": \"\"}\n  [ComfyUI]   Node 7: Preview3D\n  [ComfyUI]     Inputs: {\"model_file\": [\"6\", 0], \"image\": \"\"}\n  [ComfyUI]   Node 8: UniRigLoadRiggedMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"output\", \"refresh\": \"refresh\"}\n  [ComfyUI] Generated prompt_id: cd51d313-ff98-45b4-a7ec-58a31a90736b\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Failed to validate prompt for output 7:\n  [ComfyUI] * UniRigLoadRiggedMesh 8:\n  [ComfyUI]   - Required input is missing: fbx_file\n  [ComfyUI] Output will be ignored\n  [ComfyUI] Failed to validate prompt for output 6:\n  [ComfyUI] Output will be ignored\n  [ComfyUI] Validation result: valid=False\n  [ComfyUI]   Error: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n  [ComfyUI]   Node errors: {\"8\": {\"errors\": [{\"type\": \"required_input_missing\", \"message\": \"Required input is missing\", \"details\": \"fbx_file\", \"extra_info\": {\"input_name\": \"fbx_file\"}}], \"dependent_outputs\": [\"7\", \"6\"], \"class_type\": \"UniRigLoadRiggedMesh\"}}\n  [ComfyUI] === Validation FAILED ===\n    Status: FAILED\n    Error: Workflow validation failed\n    Details: Prompt outputs failed validation\nNode errors:\n{\n  \"8\": {\n    \"errors\": [\n      {\n        \"type\": \"required_input_missing\",\n        \"message\": \"Required input is missing\",\n        \"details\": \"fbx_file\",\n        \"extra_info\": {\n          \"input_name\": \"fbx_file\"\n        }\n      }\n    ],\n    \"dependent_outputs\": [\n      \"7\",\n      \"6\"\n    ],\n    \"class_type\": \"UniRigLoadRiggedMesh\"\n  }\n}", "hardware": {"os": "Linux-6.11.0-1018-azure-x86_64-with-glibc2.39", "cpu": "AMD EPYC 7763 64-Core Processor"}}, "rig_human_with_texture": {"src": "screenshots/rig_human_with_texture_executed.png", "title": "rig_human_with_texture", "status": "pass", "duration": "72.02", "log": "Capturing execution frames: rig_human_with_texture.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"39\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 39: UniRigAutoRig\n  [ComfyUI]     Inputs: {\"skeleton_template\": \"mixamo\", \"fbx_name\": \"\", \"target_face_count\": 50000, \"trimesh\": [\"27\", 0], \"model\": [\"40\", 0]}\n  [ComfyUI]   Node 40: UniRigLoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": false}\n  [ComfyUI] Generated prompt_id: 00b74afa-8c7b-47da-9555-0d4c8793c912\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n  [ComfyUI]   For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  [ComfyUI]     warnings.warn(\n  [ComfyUI]   01:12:52 | INFO: Data are loaded, start creating Blender stuff\n  [ComfyUI]   01:12:52 | INFO: Blender create Mesh node geometry_0\n  [ComfyUI]   01:12:53 | INFO: glTF import finished in 0.46s\n  [ComfyUI] [UniRig] Running prestartup script...\n  [ComfyUI] [UniRig] viewer_fbx.html is up to date\n  [ComfyUI] [UniRig] viewer-bundle.js is up to date\n  [ComfyUI] [UniRig] mesh_preview_fbx.js is up to date\n  [ComfyUI] [UniRig] viewer_fbx_debug.html is up to date\n  [ComfyUI] [UniRig] viewer_fbx_compare.html is up to date\n  [ComfyUI] [UniRig] debug_skeleton_widget.js is up to date\n  [ComfyUI] [UniRig] compare_skeleton_widget.js is up to date\n  [ComfyUI] [UniRig] mixamo.fbx already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] [UniRig] realistic_male_character.glb already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/realistic_male_character.glb\n  [ComfyUI] [UniRig] FinalBaseMesh.obj already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/FinalBaseMesh.obj\n  [ComfyUI] [UniRig] mixamo/Dying.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Breakdance.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Hip_Hop_Dancing.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Mma_Kick.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Capoeira.fbx already exists\n  [ComfyUI] [UniRig] smpl/amass_sample.npz already exists\n  [ComfyUI] [UniRig] smpl/dmpl_sample.npz already exists\n  [ComfyUI] [UniRig] Animation templates ready at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/animation_templates\n  [ComfyUI] [UniRig] Animation character mixamo.fbx already exists\n  [ComfyUI] [UniRig] Animation characters ready at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/animation_characters\n  [ComfyUI] [UniRig] Prestartup script completed.\n  [ComfyUI] [GeometryPack] Parsed GeomPackRemesh: 6 backends\n  [ComfyUI] [GeometryPack] Parsed GeomPackFillHoles: 2 backends\n  [ComfyUI] [GeometryPack] Generated backend_mappings.json\n  [ComfyUI] [GeometryPack] All assets already exist in /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d\n  [ComfyUI] [ComfyUI-UniRig] Initializing custom node...\n  [ComfyUI] [UniRig] Models directory: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [ComfyUI-UniRig] [OK] Node classes imported successfully\n  [ComfyUI] [ComfyUI-UniRig] [OK] Loaded successfully!\n  [ComfyUI] [GeomPack] CGAL Python package found - CGAL Isotropic Remesh node available\n  [ComfyUI] [GeomPack] Custom server routes registered\n  [ComfyUI] [UniRig FBX Files API] Returning 0 files from output directory\n  [ComfyUI] [UniRig FBX Files API] Returning 0 files from output directory\n  [ComfyUI] [unirig] Creating PersistentVenvWorker (python=/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/bin/python)\n  [ComfyUI] [unirig] \u2192 UniRigLoadModel.load_models(cache_to_gpu=bool)\n  [ComfyUI] [unirig] \u2190 UniRigLoadModel.load_models returned tuple(1 items) [16.93s]\n  [ComfyUI] [UniRigLoadMesh] Found mesh in input folder: 3d/realistic_male_character.glb\n  [ComfyUI] [UniRigLoadMesh] File extension detected: '.glb'\n  [ComfyUI] [UniRigLoadMesh] Loading: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/realistic_male_character.glb\n  [ComfyUI] [UniRigLoadMesh] Loaded type: Scene\n  [ComfyUI] [UniRigLoadMesh] Scene has 7 geometries\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_1': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_2': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_3': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_4': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_5': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_6': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh] Converting Scene to single mesh (scene has 7 geometries)\n  [ComfyUI] [UniRigLoadMesh] After dump(): visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh] After dump(): material = PBRMaterial\n  [ComfyUI] [UniRigLoadMesh] Initial mesh: 394992 vertices, 642547 faces\n  [ComfyUI] [UniRigLoadMesh] Visual type: TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]   Has UV coords: (394992, 2)\n  [ComfyUI] [UniRigLoadMesh]   Material type: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]   Has baseColorTexture!\n  [ComfyUI] [UniRigLoadMesh] Successfully loaded: 394992 vertices, 642547 faces\n  [ComfyUI] [UniRigLoadMesh] Loaded: 394992 vertices, 642547 faces\n  [ComfyUI] [unirig] \u2192 UniRigAutoRig.auto_rig(trimesh=Trimesh, model=dict, skeleton_template=str, fbx_name=str, target_face_count=int)\n  [ComfyUI] [unirig] \u2717 UniRigAutoRig.auto_rig failed after 30.67s: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI] !!! Exception during processing !!! arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI]     from .pointcept.models.PTv3Object import get_encoder as get_encoder_ptv3obj\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/__init__.py\", line 1, in <module>\n  [ComfyUI]     from .PTv3Object import PointTransformerV3Object\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/PTv3Object.py\", line 6, in <module>\n  [ComfyUI]     import spconv.pytorch as spconv\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/__init__.py\", line 7, in <module>\n  [ComfyUI]     from spconv.pytorch.core import SparseConvTensor\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/core.py\", line 21, in <module>\n  [ComfyUI]     from spconv.tools import CUDAKernelTimer\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/tools.py\", line 16, in <module>\n  [ComfyUI]     from spconv.cppconstants import CPU_ONLY_BUILD\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/cppconstants.py\", line 15, in <module>\n  [ComfyUI]     import spconv.core_cc as _ext\n  [ComfyUI] ImportError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\n  [ComfyUI]     output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\n  [ComfyUI]     return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n  [ComfyUI]     await process_inputs(input_dict, i)\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\n  [ComfyUI]     result = f(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^\n  [ComfyUI]   File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/decorator.py\", line 412, in proxy\n  [ComfyUI]     result = worker.call_method(\n  [ComfyUI]              ^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/workers/venv.py\", line 1014, in call_method\n  [ComfyUI]     raise WorkerError(\n  [ComfyUI] comfy_env.workers.base.WorkerError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI]     from .pointcept.models.PTv3Object import get_encoder as get_encoder_ptv3obj\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/__init__.py\", line 1, in <module>\n  [ComfyUI]     from .PTv3Object import PointTransformerV3Object\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/PTv3Object.py\", line 6, in <module>\n  [ComfyUI]     import spconv.pytorch as spconv\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/__init__.py\", line 7, in <module>\n  [ComfyUI]     from spconv.pytorch.core import SparseConvTensor\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/core.py\", line 21, in <module>\n  [ComfyUI]     from spconv.tools import CUDAKernelTimer\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/tools.py\", line 16, in <module>\n  [ComfyUI]     from spconv.cppconstants import CPU_ONLY_BUILD\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/cppconstants.py\", line 15, in <module>\n  [ComfyUI]     import spconv.core_cc as _ext\n  [ComfyUI] ImportError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] \n  [ComfyUI] Prompt executed in 48.93 seconds\n  Execution error: {'prompt_id': '8941b084-c248-4210-9f28-43fcc07831be', 'node_id': '39', 'node_type': 'UniRigAutoRig', 'executed': ['40', '27'], 'exception_message': 'arg(): could not convert default argument \\'workspace: tv::Tensor\\' in method \\'<class \\'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple\\'>.run_with_tuned_result\\' into a Python object (type not registered yet?)\\n\\nWorker traceback:\\nTraceback (most recent call last):\\n  File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\\n    result = method(**inputs)\\n             ^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\\n    normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\\n                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\\n    direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\\n    return func(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\\n    skeleton = predict_skeleton(\\n               ^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\\n    return func(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\\n    model, tokenizer = get_skeleton_model(checkpoint_path, device)\\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\\n    _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\\n    from src.model.parse import get_model\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\\n    from .unirig_ar import UniRigAR\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\\n    from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\\n    from .pointcept.models.PTv3Object import get_encoder as get_encoder_ptv3obj\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/__init__.py\", line 1, in <module>\\n    from .PTv3Object import PointTransformerV3Object\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/PTv3Object.py\", line 6, in <module>\\n    import spconv.pytorch as spconv\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/__init__.py\", line 7, in <module>\\n    from spconv.pytorch.core import SparseConvTensor\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/core.py\", line 21, in <module>\\n    from spconv.tools import CUDAKernelTimer\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/tools.py\", line 16, in <module>\\n    from spconv.cppconstants import CPU_ONLY_BUILD\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/cppconstants.py\", line 15, in <module>\\n    import spconv.core_cc as _ext\\nImportError: arg(): could not convert default argument \\'workspace: tv::Tensor\\' in method \\'<class \\'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple\\'>.run_with_tuned_result\\' into a Python object (type not registered yet?)\\n\\n', 'exception_type': 'comfy_env.workers.base.WorkerError', 'traceback': ['  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\\n    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\\n    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\\n    await process_inputs(input_dict, i)\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\\n    result = f(**inputs)\\n             ^^^^^^^^^^^\\n', '  File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/decorator.py\", line 412, in proxy\\n    result = worker.call_method(\\n             ^^^^^^^^^^^^^^^^^^^\\n', '  File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/workers/venv.py\", line 1014, in call_method\\n    raise WorkerError(\\n'], 'current_inputs': {'skeleton_template': ['mixamo'], 'fbx_name': [''], 'target_face_count': [50000], 'trimesh': ['<trimesh.Trimesh(vertices.shape=(394992, 3), faces.shape=(642547, 3), name=`realistic_male_character.glb`)>'], 'model': [\"{'skeleton_model': {'type': 'skeleton', 'model_id': 'apozz/UniRig-safetensors', 'task_config_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml', 'checkpoint_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors', 'model_config': {'__target__': 'unirig_ar', 'llm': {'pretrained_model_name_or_path': 'facebook/opt-350m', 'n_positions': 3076, 'max_position_embeddings': 3076, 'hidden_size': 1024, 'num_attention_heads': 16, 'num_hidden_layers': 24, 'ffn_dim': 4096, 'word_embed_proj_dim': 1024, 'do_layer_norm_before': True, '_attn_implementation': 'flash_attention_2'}, 'mesh_encoder': {'__target__': 'michelangelo_encoder', 'pretrained_path': None, 'freeze_encoder': False, 'device': 'cpu', 'dtype': 'float32', 'num_latents': 512, 'embed_dim': 64, 'point_feats': 3, 'num_freqs': 8, 'include_pi': False, 'heads': 8, 'width': 512, 'num_encoder_layers': 16, 'use_ln_post': True, 'init_scale': 0.25, 'qkv_bias': False, 'use_checkpoint': False, 'flash': True, 'supervision_type': 'sdf', 'query_method': False, 'token_num': 1024}}, 'tokenizer_config': {'method': 'tokenizer_part', 'num_discrete': 256, 'continuous_range': [-1, 1], 'cls_token_id': {'vroid': 0, 'mixamo': 1, 'articulationxl': 2}, 'parts_token_id': {'body': 0, 'hand': 1}, 'order_config': {'skeleton_path': {'vroid': './configs/skeleton/vroid.yaml', 'mixamo': './configs/skeleton/mixamo.yaml'}}}, 'unirig_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig', 'models_dir': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig', 'cached': True, 'cache_to_gpu': False, 'model_cache_key': None}, 'skinning_model': {'type': 'skinning', 'model_id': 'apozz/UniRig-safetensors', 'task_config_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/configs/task/quick_inference_unirig_skin.yaml', 'checkpoint_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors', 'model_config': {'__target__': 'unirig_skin', 'num_train_vertex': 512, 'num_heads': 16, 'feat_dim': 768, 'grid_size': 0.005, 'mlp_dim': 512, 'num_bone_attn': 8, 'num_mesh_bone_attn': 16, 'bone_embed_dim': 1024, 'voxel_mask': 3.0, 'mesh_encoder': {'__target__': 'ptv3obj', 'pretrained_path': None, 'freeze_encoder': False, 'in_channels': 9, 'cls_mode': False, 'shuffle_orders': True, 'drop_path': 0.0, 'upcast_attention': False, 'upcast_softmax': False, 'enc_depths': [3, 3, 3, 6, 16], 'enc_channels': [32, 64, 128, 256, 384], 'enc_num_head': [2, 4, 8, 16, 24], 'enable_qknorm': True, 'layer_norm': False, 'res_linear': True}, 'global_encoder': {'__target__': 'michelangelo_encoder', 'pretrained_path': None, 'freeze_encoder': False, 'device': 'cpu', 'dtype': 'float32', 'num_latents': 512, 'embed_dim': 64, 'point_feats': 3, 'num_freqs': 8, 'include_pi': False, 'heads': 8, 'width': 512, 'num_encoder_layers': 16, 'use_ln_post': True, 'init_scale': 0.25, 'qkv_bias': False, 'use_checkpoint': False, 'flash': True, 'supervision_type': 'sdf', 'query_method': False, 'token_num': 1024}}, 'unirig_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig', 'models_dir': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig', 'cached': True, 'cache_to_gpu': False, 'model_cache_key': None}, 'model_id': 'apozz/UniRig-safetensors', 'cache_to_gpu': False}\"]}, 'current_outputs': ['40', '39', '10', '27'], 'timestamp': 1769303598876}\n  Captured 164 frames over 51.14s\n  7 unique frames saved as WebP\n  Waiting 5000ms for previews to render...\n  Saved high-quality screenshot: rig_human_with_texture_executed.png\n    Captured 8 video frames", "hardware": {"os": "Linux-6.11.0-1018-azure-x86_64-with-glibc2.39", "cpu": "AMD EPYC 7763 64-Core Processor"}}, "rig_human_with_texture_mia": {"src": "screenshots/rig_human_with_texture_mia_executed.png", "title": "rig_human_with_texture_mia", "status": "pass", "duration": "194.69", "log": "Capturing execution frames: rig_human_with_texture_mia.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 9 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"42\", 0], \"preview\": \"\"}\n  Queuing workflow for execution...\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI] Generated prompt_id: 724971e3-a5ec-4943-8d1f-3e2f87ed8532\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] triangulating faces\n  [ComfyUI] No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n  [ComfyUI]   For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  [ComfyUI]     warnings.warn(\n  [ComfyUI]   [UniRig] Models directory: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig\n  [ComfyUI]   [UniRigLoadModel] Loading UniRig models...\n  [ComfyUI]   [UniRigLoadModel] GPU caching: disabled\n  [ComfyUI]   [UniRigLoadSkeletonModel] Loading skeleton model: apozz/UniRig-safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] GPU caching: disabled (will offload to CPU)\n  [ComfyUI]   [UniRigLoadSkeletonModel] Downloading/verifying checkpoint...\n  [ComfyUI]   [UniRig] Downloading skeleton.safetensors from apozz/UniRig-safetensors...\n  [ComfyUI]   [UniRig] Downloaded to: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] Checkpoint ready: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] Model configuration cached successfully\n  [ComfyUI]   [UniRigLoadSkeletonModel] Checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Loading skinning model: apozz/UniRig-safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] GPU caching: disabled (will offload to CPU)\n  [ComfyUI]   [UniRigLoadSkinningModel] Downloading/verifying checkpoint...\n  [ComfyUI]   [UniRig] Downloading skin.safetensors from apozz/UniRig-safetensors...\n  [ComfyUI]   [UniRig] Downloaded to: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Checkpoint ready: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Model configuration cached successfully\n  [ComfyUI]   [UniRigLoadSkinningModel] Checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadModel] Both models loaded successfully\n  [ComfyUI]   [UniRigAutoRig] Starting complete rigging pipeline...\n  [ComfyUI]   [UniRigAutoRig] Skeleton template: mixamo\n  [ComfyUI]   [UniRigAutoRig] Step 1/2: Extracting skeleton...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Starting skeleton extraction (cached model only)...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Skeleton template: mixamo\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mixamo requested, using vroid extraction + name remapping\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using pre-loaded cached model\n  [ComfyUI]   [UniRigExtractSkeletonNew] Exporting mesh to /tmp/tmp4f5eddu9/input.glb\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mesh has 394992 vertices, 642547 faces\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mesh exported in 0.35s\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using target face count: 50000\n  [ComfyUI]   [UniRig] Loaded direct preprocessing module from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct_preprocess.py\n  [ComfyUI]   [UniRigExtractSkeletonNew] Step 1: Preprocessing mesh with direct bpy...\n  [ComfyUI]   [Direct Preprocess] Input: /tmp/tmp4f5eddu9/input.glb\n  [ComfyUI]   [Direct Preprocess] Output: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [Direct Preprocess] Target faces: 50000\n  [ComfyUI]   [Direct Preprocess] Loading .glb file...\n  [ComfyUI]   [Direct Preprocess] Import successful\n  [ComfyUI]   [Direct Preprocess] Found 1 mesh(es)\n  [ComfyUI]   [Direct Preprocess] Processing mesh: geometry_0\n  [ComfyUI]   [Direct Preprocess] Triangulating...\n  [ComfyUI]   [Direct Preprocess] Current face count: 642547\n  [ComfyUI]   [Direct Preprocess] Decimating to 50000 faces...\n  [ComfyUI]   [Direct Preprocess] Decimated to 50000 faces\n  [ComfyUI]   [Direct Preprocess] Extracted 71646 vertices, 50000 faces\n  [ComfyUI]   [Direct Preprocess] Calculated vertex normals\n  [ComfyUI]   [Direct Preprocess] Calculated face normals\n  [ComfyUI]   [Direct Preprocess] Extracted UV coordinates: 150000 UVs for 50000 faces\n  [ComfyUI]   [Direct Preprocess] Found texture node: Image Texture\n  [ComfyUI]   [Direct Preprocess] Texture path:\n  [ComfyUI]   [Direct Preprocess] Extracting texture: 1024x1024, 4 channels\n  [ComfyUI]   [Direct Preprocess] Texture encoded: 1331.3 KB base64\n  [ComfyUI]   [Direct Preprocess] Texture extracted successfully: 1024x1024 PNG\n  [ComfyUI]   [Direct Preprocess] Material: tripo_mat_d0bcade7\n  [ComfyUI]   [Direct Preprocess] Saved to: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [Direct Preprocess] Texture data included: 1024x1024 PNG\n  [ComfyUI]   [Direct Preprocess] Done!\n  [ComfyUI]   [UniRigExtractSkeletonNew] [OK] Mesh preprocessed in 16.52s: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [UniRigExtractSkeletonNew] Forcing skeleton template: vroid\n  [ComfyUI]   [UniRig] Loaded direct inference module from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\n  [ComfyUI]   [UniRigExtractSkeletonNew] Step 2: Running skeleton inference...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [MIALoadModel] Loading Make-It-Animatable models...\n  [ComfyUI]   [MIALoadModel] GPU caching: enabled\n  [ComfyUI]   [MIA] Downloading missing models: ['bw.pth', 'bw_normal.pth', 'joints.pth', 'joints_coarse.pth', 'pose.pth']\n  [ComfyUI]   [MIA] Downloading bw.pth...\n  [ComfyUI]   [MIA] Downloading bw_normal.pth...\n  [ComfyUI]   [MIA] Downloading joints.pth...\n  [ComfyUI]   [MIA] Downloading joints_coarse.pth...\n  [ComfyUI]   [MIA] Downloading pose.pth...\n  [ComfyUI]   [MIA] All models downloaded successfully\n  [ComfyUI]   [MIA] Loading models to cpu...\n  [ComfyUI]   [MIA] Loading joints_coarse model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/joints_coarse.pth\n  [ComfyUI]   [MIA] Loading bw model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/bw.pth\n  [ComfyUI]   [MIA] Loading bw_normal model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/bw_normal.pth\n  [ComfyUI]   [MIA] Loading joints model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/joints.pth\n  [ComfyUI]   [MIA] Loading pose model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/pose.pth\n  [ComfyUI]   [MIA] All models loaded successfully\n  [ComfyUI]   [MIALoadModel] Models loaded successfully\n  [ComfyUI]   [MIAAutoRig] Starting Make-It-Animatable rigging pipeline...\n  [ComfyUI]   [MIAAutoRig] Options: no_fingers=False, use_normal=False, reset_to_rest=True\n  [ComfyUI]   [MIA] Starting inference...\n  [ComfyUI]   [MIA] Options: no_fingers=False, use_normal=False, reset_to_rest=True\n  [ComfyUI]   [MIA] Input mesh: 394992 vertices, 642547 faces\n  [ComfyUI]   [MIA] Input mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA]   Material type: PBRMaterial\n  [ComfyUI]   [MIA]   Has baseColorTexture!\n  [ComfyUI]   [MIA] Preparing input...\n  [ComfyUI]   [MIA] After prepare_input: data.mesh has 394992 vertices\n  [ComfyUI]   [MIA]   data.mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA]   Has material: PBRMaterial\n  [ComfyUI]   [MIA] Preprocessing...\n  [ComfyUI]   [MIA] Running model inference...\n  [ComfyUI]   [MIA] Post-processing...\n  [ComfyUI]   [MIA] reset_to_rest=True, data.pose is None: False\n  [ComfyUI]   [MIA] Pose shape: torch.Size([1, 52, 6])\n  [ComfyUI]   [MIA] Saved pose data to /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/temp/mia_pose_debug.npy\n  [ComfyUI]   [MIA] Exporting to FBX...\n  [ComfyUI]   [MIA] Using bpy directly for FBX export...\n  [ComfyUI]   [MIA Export] Mesh to export: 394992 vertices, 642547 faces\n  [ComfyUI]   [MIA Export] Mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA Export]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA Export]   Material type: PBRMaterial\n  [ComfyUI]   [MIA Export]   Has baseColorTexture!\n  [ComfyUI]   [MIA Export] About to export mesh to: /tmp/tmpslb97xmk.glb\n  [ComfyUI]   [MIA Export] Mesh has visual: True\n  [ComfyUI]   [MIA Export] Visual kind: texture\n  [ComfyUI]   [MIA Export] Has UV: shape=(394992, 2)\n  [ComfyUI]   [MIA Export] Material: PBRMaterial\n  [ComfyUI]   [MIA Export]   baseColorTexture: Image\n  [ComfyUI]   [MIA Export] Exported GLB size: 16287072 bytes\n  [ComfyUI]   [MIA Export] Weights: (394992, 52), Joints: (52, 3), Bones: 52\n  [ComfyUI]   FBX version: 7700\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported01:14:56 | INFO: Data are loaded, start creating Blender stuff\n  [ComfyUI]   01:14:56 | INFO: Blender create Mesh node geometry_0\n  [ComfyUI]   01:14:56 | INFO: glTF import finished in 0.62s\n  [ComfyUI]   01:15:52 | INFO: Starting glTF 2.0 export\n  [ComfyUI]   01:15:53 | INFO: Extracting primitive: geometry_0\n  [ComfyUI]   01:15:57 | INFO: Primitives created: 1\n  [ComfyUI]   01:15:57 | WARNING: There are more than 4 joint vertex influences.The 4 with highest weight will be used (and normalized).\n  [ComfyUI]   01:15:59 | INFO: Finished glTF 2.0 export in 6.365877628326416 s\n  [ComfyUI] triangulating faces\n  [ComfyUI] Prompt executed in 139.31 seconds\n  Captured 466 frames over 155.22s\n  8 unique frames saved as WebP\n  Waiting 5000ms for previews to render...\n  Saved high-quality screenshot: rig_human_with_texture_mia_executed.png\n    Captured 9 video frames", "hardware": {"os": "Linux-6.11.0-1018-azure-x86_64-with-glibc2.39", "cpu": "AMD EPYC 7763 64-Core Processor"}}, "rig_human_with_texture_mia_debug": {"src": "screenshots/rig_human_with_texture_mia_debug_executed.png", "title": "rig_human_with_texture_mia_debug", "status": "pass", "duration": "15.62", "log": "Capturing execution frames: rig_human_with_texture_mia_debug.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI]   Node 49: UniRigCompareSkeletons\n  [ComfyUI]     Inputs: {\"fbx_path_left\": [\"42\", 0], \"fbx_path_right\": [\"51\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 50: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/mixamo.fbx\"}\n  [ComfyUI]   Node 51: PrimitiveString\n  [ComfyUI]     Inputs: {\"value\": \"/home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\"}\n  [ComfyUI] Generated prompt_id: fb321b26-dd6d-4d99-acc9-964590049773\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] !!! Exception during processing !!! Right FBX file not found: /home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\n  [ComfyUI]     output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\n  [ComfyUI]     return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n  [ComfyUI]     await process_inputs(input_dict, i)\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\n  [ComfyUI]     result = f(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/nodes/skeleton_io.py\", line 633, in compare_skeletons\n  [ComfyUI]     raise RuntimeError(f\"Right FBX file not found: {fbx_path_right}\")\n  [ComfyUI] RuntimeError: Right FBX file not found: /home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] \n  [ComfyUI] Prompt executed in 0.01 seconds\n  Execution error: {'prompt_id': '6217613b-7a19-47ac-8f2c-a494e6a57486', 'node_id': '49', 'node_type': 'UniRigCompareSkeletons', 'executed': ['51'], 'exception_message': 'Right FBX file not found: /home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\\n', 'exception_type': 'RuntimeError', 'traceback': ['  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\\n    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\\n    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\\n    await process_inputs(input_dict, i)\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\\n    result = f(**inputs)\\n             ^^^^^^^^^^^\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/nodes/skeleton_io.py\", line 633, in compare_skeletons\\n    raise RuntimeError(f\"Right FBX file not found: {fbx_path_right}\")\\n'], 'current_inputs': {'fbx_path_left': ['/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/output/rigatoni_mia.fbx'], 'fbx_path_right': ['/home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx']}, 'current_outputs': ['46', '47', '45', '43', '49', '44', '42', '27', '50', '51', '41'], 'timestamp': 1769303817830}\n  Captured 5 frames over 1.84s\n  4 unique frames saved as WebP\n  Waiting 5000ms for previews to render...\n  Saved high-quality screenshot: rig_human_with_texture_mia_debug_executed.png\n    Captured 5 video frames", "hardware": {"os": "Linux-6.11.0-1018-azure-x86_64-with-glibc2.39", "cpu": "AMD EPYC 7763 64-Core Processor"}}, "rigged_manipulator": {"src": "screenshots/rigged_manipulator_executed.png", "title": "rigged_manipulator", "status": "pass", "duration": "33.04", "log": "Capturing execution frames: rigged_manipulator.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 2 nodes\n  [ComfyUI]   Node 1: UniRigLoadRiggedMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"output\", \"fbx_file\": \"rigatoni_mia.fbx\", \"refresh\": \"refresh\"}\n  [ComfyUI]   Node 3: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"1\", 0], \"preview\": \"\"}\n  [ComfyUI] Generated prompt_id: 8d48df75-588a-468c-bdab-d59d48e75f09\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] Prompt executed in 0.01 seconds\n  Captured 5 frames over 15.96s\n  4 unique frames saved as WebP\n  Waiting 5000ms for previews to render...\n  Saved high-quality screenshot: rigged_manipulator_executed.png\n    Captured 5 video frames", "hardware": {"os": "Linux-6.11.0-1018-azure-x86_64-with-glibc2.39", "cpu": "AMD EPYC 7763 64-Core Processor"}}};

        // Store video metadata (frames with timestamps and logs)
        const videoData = {"rigged_manipulator": {"frames": [{"file": "frame_000.jpg", "time": 0.0, "log": "Capturing execution frames: rigged_manipulator.json"}, {"file": "frame_001.jpg", "time": 0.22, "log": "Capturing execution frames: rigged_manipulator.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 2 nodes\n  [ComfyUI]   Node 1: UniRigLoadRiggedMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"output\", \"fbx_file\": \"rigatoni_mia.fbx\", \"refresh\": \"refresh\"}\n  [ComfyUI]   Node 3: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"1\", 0], \"preview\": \"\"}\n  [ComfyUI] Generated prompt_id: 8d48df75-588a-468c-bdab-d59d48e75f09\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] Prompt executed in 0.01 seconds"}, {"file": "frame_002.jpg", "time": 0.52, "log": "Capturing execution frames: rigged_manipulator.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 2 nodes\n  [ComfyUI]   Node 1: UniRigLoadRiggedMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"output\", \"fbx_file\": \"rigatoni_mia.fbx\", \"refresh\": \"refresh\"}\n  [ComfyUI]   Node 3: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"1\", 0], \"preview\": \"\"}\n  [ComfyUI] Generated prompt_id: 8d48df75-588a-468c-bdab-d59d48e75f09\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] Prompt executed in 0.01 seconds"}, {"file": "frame_003.jpg", "time": 8.02, "log": "Capturing execution frames: rigged_manipulator.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 2 nodes\n  [ComfyUI]   Node 1: UniRigLoadRiggedMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"output\", \"fbx_file\": \"rigatoni_mia.fbx\", \"refresh\": \"refresh\"}\n  [ComfyUI]   Node 3: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"1\", 0], \"preview\": \"\"}\n  [ComfyUI] Generated prompt_id: 8d48df75-588a-468c-bdab-d59d48e75f09\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] Prompt executed in 0.01 seconds"}, {"file": "frame_004.jpg", "time": 28.179793119430542, "log": "Final screenshot"}], "total_time": 15.96}, "rig_human_with_texture": {"frames": [{"file": "frame_000.jpg", "time": 0.0, "log": "Capturing execution frames: rig_human_with_texture.json"}, {"file": "frame_001.jpg", "time": 0.45, "log": "Capturing execution frames: rig_human_with_texture.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"39\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 39: UniRigAutoRig\n  [ComfyUI]     Inputs: {\"skeleton_template\": \"mixamo\", \"fbx_name\": \"\", \"target_face_count\": 50000, \"trimesh\": [\"27\", 0], \"model\": [\"40\", 0]}\n  [ComfyUI]   Node 40: UniRigLoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": false}\n  [ComfyUI] Generated prompt_id: 00b74afa-8c7b-47da-9555-0d4c8793c912\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt"}, {"file": "frame_002.jpg", "time": 17.33, "log": "Capturing execution frames: rig_human_with_texture.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"39\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 39: UniRigAutoRig\n  [ComfyUI]     Inputs: {\"skeleton_template\": \"mixamo\", \"fbx_name\": \"\", \"target_face_count\": 50000, \"trimesh\": [\"27\", 0], \"model\": [\"40\", 0]}\n  [ComfyUI]   Node 40: UniRigLoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": false}\n  [ComfyUI] Generated prompt_id: 00b74afa-8c7b-47da-9555-0d4c8793c912\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`."}, {"file": "frame_003.jpg", "time": 18.67, "log": "Capturing execution frames: rig_human_with_texture.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"39\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 39: UniRigAutoRig\n  [ComfyUI]     Inputs: {\"skeleton_template\": \"mixamo\", \"fbx_name\": \"\", \"target_face_count\": 50000, \"trimesh\": [\"27\", 0], \"model\": [\"40\", 0]}\n  [ComfyUI]   Node 40: UniRigLoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": false}\n  [ComfyUI] Generated prompt_id: 00b74afa-8c7b-47da-9555-0d4c8793c912\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`."}, {"file": "frame_004.jpg", "time": 49.23, "log": "Capturing execution frames: rig_human_with_texture.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"39\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 39: UniRigAutoRig\n  [ComfyUI]     Inputs: {\"skeleton_template\": \"mixamo\", \"fbx_name\": \"\", \"target_face_count\": 50000, \"trimesh\": [\"27\", 0], \"model\": [\"40\", 0]}\n  [ComfyUI]   Node 40: UniRigLoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": false}\n  [ComfyUI] Generated prompt_id: 00b74afa-8c7b-47da-9555-0d4c8793c912\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n  [ComfyUI]   For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  [ComfyUI]     warnings.warn(\n  [ComfyUI]   01:12:52 | INFO: Data are loaded, start creating Blender stuff\n  [ComfyUI]   01:12:52 | INFO: Blender create Mesh node geometry_0\n  [ComfyUI]   01:12:53 | INFO: glTF import finished in 0.46s\n  [ComfyUI] [UniRig] Running prestartup script...\n  [ComfyUI] [UniRig] viewer_fbx.html is up to date\n  [ComfyUI] [UniRig] viewer-bundle.js is up to date\n  [ComfyUI] [UniRig] mesh_preview_fbx.js is up to date\n  [ComfyUI] [UniRig] viewer_fbx_debug.html is up to date\n  [ComfyUI] [UniRig] viewer_fbx_compare.html is up to date\n  [ComfyUI] [UniRig] debug_skeleton_widget.js is up to date\n  [ComfyUI] [UniRig] compare_skeleton_widget.js is up to date\n  [ComfyUI] [UniRig] mixamo.fbx already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] [UniRig] realistic_male_character.glb already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/realistic_male_character.glb\n  [ComfyUI] [UniRig] FinalBaseMesh.obj already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/FinalBaseMesh.obj\n  [ComfyUI] [UniRig] mixamo/Dying.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Breakdance.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Hip_Hop_Dancing.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Mma_Kick.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Capoeira.fbx already exists\n  [ComfyUI] [UniRig] smpl/amass_sample.npz already exists\n  [ComfyUI] [UniRig] smpl/dmpl_sample.npz already exists\n  [ComfyUI] [UniRig] Animation templates ready at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/animation_templates\n  [ComfyUI] [UniRig] Animation character mixamo.fbx already exists\n  [ComfyUI] [UniRig] Animation characters ready at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/animation_characters\n  [ComfyUI] [UniRig] Prestartup script completed.\n  [ComfyUI] [GeometryPack] Parsed GeomPackRemesh: 6 backends\n  [ComfyUI] [GeometryPack] Parsed GeomPackFillHoles: 2 backends\n  [ComfyUI] [GeometryPack] Generated backend_mappings.json\n  [ComfyUI] [GeometryPack] All assets already exist in /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d\n  [ComfyUI] [ComfyUI-UniRig] Initializing custom node...\n  [ComfyUI] [UniRig] Models directory: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [ComfyUI-UniRig] [OK] Node classes imported successfully\n  [ComfyUI] [ComfyUI-UniRig] [OK] Loaded successfully!\n  [ComfyUI] [GeomPack] CGAL Python package found - CGAL Isotropic Remesh node available\n  [ComfyUI] [GeomPack] Custom server routes registered\n  [ComfyUI] [UniRig FBX Files API] Returning 0 files from output directory\n  [ComfyUI] [UniRig FBX Files API] Returning 0 files from output directory\n  [ComfyUI] [unirig] Creating PersistentVenvWorker (python=/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/bin/python)\n  [ComfyUI] [unirig] \u2192 UniRigLoadModel.load_models(cache_to_gpu=bool)\n  [ComfyUI] [unirig] \u2190 UniRigLoadModel.load_models returned tuple(1 items) [16.93s]\n  [ComfyUI] [UniRigLoadMesh] Found mesh in input folder: 3d/realistic_male_character.glb\n  [ComfyUI] [UniRigLoadMesh] File extension detected: '.glb'\n  [ComfyUI] [UniRigLoadMesh] Loading: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/realistic_male_character.glb\n  [ComfyUI] [UniRigLoadMesh] Loaded type: Scene\n  [ComfyUI] [UniRigLoadMesh] Scene has 7 geometries\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_1': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_2': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_3': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_4': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_5': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_6': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh] Converting Scene to single mesh (scene has 7 geometries)\n  [ComfyUI] [UniRigLoadMesh] After dump(): visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh] After dump(): material = PBRMaterial\n  [ComfyUI] [UniRigLoadMesh] Initial mesh: 394992 vertices, 642547 faces\n  [ComfyUI] [UniRigLoadMesh] Visual type: TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]   Has UV coords: (394992, 2)\n  [ComfyUI] [UniRigLoadMesh]   Material type: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]   Has baseColorTexture!\n  [ComfyUI] [UniRigLoadMesh] Successfully loaded: 394992 vertices, 642547 faces\n  [ComfyUI] [UniRigLoadMesh] Loaded: 394992 vertices, 642547 faces\n  [ComfyUI] [unirig] \u2192 UniRigAutoRig.auto_rig(trimesh=Trimesh, model=dict, skeleton_template=str, fbx_name=str, target_face_count=int)\n  [ComfyUI] [unirig] \u2717 UniRigAutoRig.auto_rig failed after 30.67s: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI] !!! Exception during processing !!! arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI]     from .pointcept.models.PTv3Object import get_encoder as get_encoder_ptv3obj\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/__init__.py\", line 1, in <module>\n  [ComfyUI]     from .PTv3Object import PointTransformerV3Object\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/PTv3Object.py\", line 6, in <module>\n  [ComfyUI]     import spconv.pytorch as spconv\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/__init__.py\", line 7, in <module>\n  [ComfyUI]     from spconv.pytorch.core import SparseConvTensor\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/core.py\", line 21, in <module>\n  [ComfyUI]     from spconv.tools import CUDAKernelTimer\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/tools.py\", line 16, in <module>\n  [ComfyUI]     from spconv.cppconstants import CPU_ONLY_BUILD\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/cppconstants.py\", line 15, in <module>\n  [ComfyUI]     import spconv.core_cc as _ext\n  [ComfyUI] ImportError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\n  [ComfyUI]     output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\n  [ComfyUI]     return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n  [ComfyUI]     await process_inputs(input_dict, i)\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\n  [ComfyUI]     result = f(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^\n  [ComfyUI]   File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/decorator.py\", line 412, in proxy\n  [ComfyUI]     result = worker.call_method(\n  [ComfyUI]              ^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/workers/venv.py\", line 1014, in call_method\n  [ComfyUI]     raise WorkerError(\n  [ComfyUI] comfy_env.workers.base.WorkerError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI]     from .pointcept.models.PTv3Object import get_encoder as get_encoder_ptv3obj\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/__init__.py\", line 1, in <module>\n  [ComfyUI]     from .PTv3Object import PointTransformerV3Object\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/PTv3Object.py\", line 6, in <module>\n  [ComfyUI]     import spconv.pytorch as spconv\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/__init__.py\", line 7, in <module>\n  [ComfyUI]     from spconv.pytorch.core import SparseConvTensor\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/core.py\", line 21, in <module>\n  [ComfyUI]     from spconv.tools import CUDAKernelTimer\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/tools.py\", line 16, in <module>\n  [ComfyUI]     from spconv.cppconstants import CPU_ONLY_BUILD\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/cppconstants.py\", line 15, in <module>\n  [ComfyUI]     import spconv.core_cc as _ext\n  [ComfyUI] ImportError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] \n  [ComfyUI] Prompt executed in 48.93 seconds"}, {"file": "frame_005.jpg", "time": 49.7, "log": "Capturing execution frames: rig_human_with_texture.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"39\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 39: UniRigAutoRig\n  [ComfyUI]     Inputs: {\"skeleton_template\": \"mixamo\", \"fbx_name\": \"\", \"target_face_count\": 50000, \"trimesh\": [\"27\", 0], \"model\": [\"40\", 0]}\n  [ComfyUI]   Node 40: UniRigLoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": false}\n  [ComfyUI] Generated prompt_id: 00b74afa-8c7b-47da-9555-0d4c8793c912\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n  [ComfyUI]   For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  [ComfyUI]     warnings.warn(\n  [ComfyUI]   01:12:52 | INFO: Data are loaded, start creating Blender stuff\n  [ComfyUI]   01:12:52 | INFO: Blender create Mesh node geometry_0\n  [ComfyUI]   01:12:53 | INFO: glTF import finished in 0.46s\n  [ComfyUI] [UniRig] Running prestartup script...\n  [ComfyUI] [UniRig] viewer_fbx.html is up to date\n  [ComfyUI] [UniRig] viewer-bundle.js is up to date\n  [ComfyUI] [UniRig] mesh_preview_fbx.js is up to date\n  [ComfyUI] [UniRig] viewer_fbx_debug.html is up to date\n  [ComfyUI] [UniRig] viewer_fbx_compare.html is up to date\n  [ComfyUI] [UniRig] debug_skeleton_widget.js is up to date\n  [ComfyUI] [UniRig] compare_skeleton_widget.js is up to date\n  [ComfyUI] [UniRig] mixamo.fbx already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] [UniRig] realistic_male_character.glb already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/realistic_male_character.glb\n  [ComfyUI] [UniRig] FinalBaseMesh.obj already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/FinalBaseMesh.obj\n  [ComfyUI] [UniRig] mixamo/Dying.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Breakdance.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Hip_Hop_Dancing.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Mma_Kick.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Capoeira.fbx already exists\n  [ComfyUI] [UniRig] smpl/amass_sample.npz already exists\n  [ComfyUI] [UniRig] smpl/dmpl_sample.npz already exists\n  [ComfyUI] [UniRig] Animation templates ready at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/animation_templates\n  [ComfyUI] [UniRig] Animation character mixamo.fbx already exists\n  [ComfyUI] [UniRig] Animation characters ready at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/animation_characters\n  [ComfyUI] [UniRig] Prestartup script completed.\n  [ComfyUI] [GeometryPack] Parsed GeomPackRemesh: 6 backends\n  [ComfyUI] [GeometryPack] Parsed GeomPackFillHoles: 2 backends\n  [ComfyUI] [GeometryPack] Generated backend_mappings.json\n  [ComfyUI] [GeometryPack] All assets already exist in /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d\n  [ComfyUI] [ComfyUI-UniRig] Initializing custom node...\n  [ComfyUI] [UniRig] Models directory: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [ComfyUI-UniRig] [OK] Node classes imported successfully\n  [ComfyUI] [ComfyUI-UniRig] [OK] Loaded successfully!\n  [ComfyUI] [GeomPack] CGAL Python package found - CGAL Isotropic Remesh node available\n  [ComfyUI] [GeomPack] Custom server routes registered\n  [ComfyUI] [UniRig FBX Files API] Returning 0 files from output directory\n  [ComfyUI] [UniRig FBX Files API] Returning 0 files from output directory\n  [ComfyUI] [unirig] Creating PersistentVenvWorker (python=/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/bin/python)\n  [ComfyUI] [unirig] \u2192 UniRigLoadModel.load_models(cache_to_gpu=bool)\n  [ComfyUI] [unirig] \u2190 UniRigLoadModel.load_models returned tuple(1 items) [16.93s]\n  [ComfyUI] [UniRigLoadMesh] Found mesh in input folder: 3d/realistic_male_character.glb\n  [ComfyUI] [UniRigLoadMesh] File extension detected: '.glb'\n  [ComfyUI] [UniRigLoadMesh] Loading: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/realistic_male_character.glb\n  [ComfyUI] [UniRigLoadMesh] Loaded type: Scene\n  [ComfyUI] [UniRigLoadMesh] Scene has 7 geometries\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_1': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_2': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_3': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_4': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_5': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_6': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh] Converting Scene to single mesh (scene has 7 geometries)\n  [ComfyUI] [UniRigLoadMesh] After dump(): visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh] After dump(): material = PBRMaterial\n  [ComfyUI] [UniRigLoadMesh] Initial mesh: 394992 vertices, 642547 faces\n  [ComfyUI] [UniRigLoadMesh] Visual type: TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]   Has UV coords: (394992, 2)\n  [ComfyUI] [UniRigLoadMesh]   Material type: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]   Has baseColorTexture!\n  [ComfyUI] [UniRigLoadMesh] Successfully loaded: 394992 vertices, 642547 faces\n  [ComfyUI] [UniRigLoadMesh] Loaded: 394992 vertices, 642547 faces\n  [ComfyUI] [unirig] \u2192 UniRigAutoRig.auto_rig(trimesh=Trimesh, model=dict, skeleton_template=str, fbx_name=str, target_face_count=int)\n  [ComfyUI] [unirig] \u2717 UniRigAutoRig.auto_rig failed after 30.67s: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI] !!! Exception during processing !!! arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI]     from .pointcept.models.PTv3Object import get_encoder as get_encoder_ptv3obj\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/__init__.py\", line 1, in <module>\n  [ComfyUI]     from .PTv3Object import PointTransformerV3Object\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/PTv3Object.py\", line 6, in <module>\n  [ComfyUI]     import spconv.pytorch as spconv\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/__init__.py\", line 7, in <module>\n  [ComfyUI]     from spconv.pytorch.core import SparseConvTensor\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/core.py\", line 21, in <module>\n  [ComfyUI]     from spconv.tools import CUDAKernelTimer\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/tools.py\", line 16, in <module>\n  [ComfyUI]     from spconv.cppconstants import CPU_ONLY_BUILD\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/cppconstants.py\", line 15, in <module>\n  [ComfyUI]     import spconv.core_cc as _ext\n  [ComfyUI] ImportError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\n  [ComfyUI]     output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\n  [ComfyUI]     return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n  [ComfyUI]     await process_inputs(input_dict, i)\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\n  [ComfyUI]     result = f(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^\n  [ComfyUI]   File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/decorator.py\", line 412, in proxy\n  [ComfyUI]     result = worker.call_method(\n  [ComfyUI]              ^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/workers/venv.py\", line 1014, in call_method\n  [ComfyUI]     raise WorkerError(\n  [ComfyUI] comfy_env.workers.base.WorkerError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI]     from .pointcept.models.PTv3Object import get_encoder as get_encoder_ptv3obj\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/__init__.py\", line 1, in <module>\n  [ComfyUI]     from .PTv3Object import PointTransformerV3Object\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/PTv3Object.py\", line 6, in <module>\n  [ComfyUI]     import spconv.pytorch as spconv\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/__init__.py\", line 7, in <module>\n  [ComfyUI]     from spconv.pytorch.core import SparseConvTensor\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/core.py\", line 21, in <module>\n  [ComfyUI]     from spconv.tools import CUDAKernelTimer\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/tools.py\", line 16, in <module>\n  [ComfyUI]     from spconv.cppconstants import CPU_ONLY_BUILD\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/cppconstants.py\", line 15, in <module>\n  [ComfyUI]     import spconv.core_cc as _ext\n  [ComfyUI] ImportError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] \n  [ComfyUI] Prompt executed in 48.93 seconds"}, {"file": "frame_006.jpg", "time": 50.9, "log": "Capturing execution frames: rig_human_with_texture.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"39\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 39: UniRigAutoRig\n  [ComfyUI]     Inputs: {\"skeleton_template\": \"mixamo\", \"fbx_name\": \"\", \"target_face_count\": 50000, \"trimesh\": [\"27\", 0], \"model\": [\"40\", 0]}\n  [ComfyUI]   Node 40: UniRigLoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": false}\n  [ComfyUI] Generated prompt_id: 00b74afa-8c7b-47da-9555-0d4c8793c912\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n  [ComfyUI]   For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  [ComfyUI]     warnings.warn(\n  [ComfyUI]   01:12:52 | INFO: Data are loaded, start creating Blender stuff\n  [ComfyUI]   01:12:52 | INFO: Blender create Mesh node geometry_0\n  [ComfyUI]   01:12:53 | INFO: glTF import finished in 0.46s\n  [ComfyUI] [UniRig] Running prestartup script...\n  [ComfyUI] [UniRig] viewer_fbx.html is up to date\n  [ComfyUI] [UniRig] viewer-bundle.js is up to date\n  [ComfyUI] [UniRig] mesh_preview_fbx.js is up to date\n  [ComfyUI] [UniRig] viewer_fbx_debug.html is up to date\n  [ComfyUI] [UniRig] viewer_fbx_compare.html is up to date\n  [ComfyUI] [UniRig] debug_skeleton_widget.js is up to date\n  [ComfyUI] [UniRig] compare_skeleton_widget.js is up to date\n  [ComfyUI] [UniRig] mixamo.fbx already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] [UniRig] realistic_male_character.glb already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/realistic_male_character.glb\n  [ComfyUI] [UniRig] FinalBaseMesh.obj already exists at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/FinalBaseMesh.obj\n  [ComfyUI] [UniRig] mixamo/Dying.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Breakdance.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Hip_Hop_Dancing.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Mma_Kick.fbx already exists\n  [ComfyUI] [UniRig] mixamo/Capoeira.fbx already exists\n  [ComfyUI] [UniRig] smpl/amass_sample.npz already exists\n  [ComfyUI] [UniRig] smpl/dmpl_sample.npz already exists\n  [ComfyUI] [UniRig] Animation templates ready at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/animation_templates\n  [ComfyUI] [UniRig] Animation character mixamo.fbx already exists\n  [ComfyUI] [UniRig] Animation characters ready at /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/animation_characters\n  [ComfyUI] [UniRig] Prestartup script completed.\n  [ComfyUI] [GeometryPack] Parsed GeomPackRemesh: 6 backends\n  [ComfyUI] [GeometryPack] Parsed GeomPackFillHoles: 2 backends\n  [ComfyUI] [GeometryPack] Generated backend_mappings.json\n  [ComfyUI] [GeometryPack] All assets already exist in /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d\n  [ComfyUI] [ComfyUI-UniRig] Initializing custom node...\n  [ComfyUI] [UniRig] Models directory: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [unirig] Auto-discovered v2 config: unirig\n  [ComfyUI] [ComfyUI-UniRig] [OK] Node classes imported successfully\n  [ComfyUI] [ComfyUI-UniRig] [OK] Loaded successfully!\n  [ComfyUI] [GeomPack] CGAL Python package found - CGAL Isotropic Remesh node available\n  [ComfyUI] [GeomPack] Custom server routes registered\n  [ComfyUI] [UniRig FBX Files API] Returning 0 files from output directory\n  [ComfyUI] [UniRig FBX Files API] Returning 0 files from output directory\n  [ComfyUI] [unirig] Creating PersistentVenvWorker (python=/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/bin/python)\n  [ComfyUI] [unirig] \u2192 UniRigLoadModel.load_models(cache_to_gpu=bool)\n  [ComfyUI] [unirig] \u2190 UniRigLoadModel.load_models returned tuple(1 items) [16.93s]\n  [ComfyUI] [UniRigLoadMesh] Found mesh in input folder: 3d/realistic_male_character.glb\n  [ComfyUI] [UniRigLoadMesh] File extension detected: '.glb'\n  [ComfyUI] [UniRigLoadMesh] Loading: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/input/3d/realistic_male_character.glb\n  [ComfyUI] [UniRigLoadMesh] Loaded type: Scene\n  [ComfyUI] [UniRigLoadMesh] Scene has 7 geometries\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_1': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_2': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_3': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_4': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_5': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh]   Geometry 'tripo_node_d0bcade7_tripo_mat_d0bcade7_0_6': visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]     Material: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]     Has baseColorTexture: yes\n  [ComfyUI] [UniRigLoadMesh] Converting Scene to single mesh (scene has 7 geometries)\n  [ComfyUI] [UniRigLoadMesh] After dump(): visual type = TextureVisuals\n  [ComfyUI] [UniRigLoadMesh] After dump(): material = PBRMaterial\n  [ComfyUI] [UniRigLoadMesh] Initial mesh: 394992 vertices, 642547 faces\n  [ComfyUI] [UniRigLoadMesh] Visual type: TextureVisuals\n  [ComfyUI] [UniRigLoadMesh]   Has UV coords: (394992, 2)\n  [ComfyUI] [UniRigLoadMesh]   Material type: PBRMaterial\n  [ComfyUI] [UniRigLoadMesh]   Has baseColorTexture!\n  [ComfyUI] [UniRigLoadMesh] Successfully loaded: 394992 vertices, 642547 faces\n  [ComfyUI] [UniRigLoadMesh] Loaded: 394992 vertices, 642547 faces\n  [ComfyUI] [unirig] \u2192 UniRigAutoRig.auto_rig(trimesh=Trimesh, model=dict, skeleton_template=str, fbx_name=str, target_face_count=int)\n  [ComfyUI] [unirig] \u2717 UniRigAutoRig.auto_rig failed after 30.67s: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI] !!! Exception during processing !!! arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI]     from .pointcept.models.PTv3Object import get_encoder as get_encoder_ptv3obj\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/__init__.py\", line 1, in <module>\n  [ComfyUI]     from .PTv3Object import PointTransformerV3Object\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/PTv3Object.py\", line 6, in <module>\n  [ComfyUI]     import spconv.pytorch as spconv\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/__init__.py\", line 7, in <module>\n  [ComfyUI]     from spconv.pytorch.core import SparseConvTensor\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/core.py\", line 21, in <module>\n  [ComfyUI]     from spconv.tools import CUDAKernelTimer\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/tools.py\", line 16, in <module>\n  [ComfyUI]     from spconv.cppconstants import CPU_ONLY_BUILD\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/cppconstants.py\", line 15, in <module>\n  [ComfyUI]     import spconv.core_cc as _ext\n  [ComfyUI] ImportError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\n  [ComfyUI]     output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\n  [ComfyUI]     return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n  [ComfyUI]     await process_inputs(input_dict, i)\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\n  [ComfyUI]     result = f(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^\n  [ComfyUI]   File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/decorator.py\", line 412, in proxy\n  [ComfyUI]     result = worker.call_method(\n  [ComfyUI]              ^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/workers/venv.py\", line 1014, in call_method\n  [ComfyUI]     raise WorkerError(\n  [ComfyUI] comfy_env.workers.base.WorkerError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] Worker traceback:\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\n  [ComfyUI]     result = method(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\n  [ComfyUI]     normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\n  [ComfyUI]                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\n  [ComfyUI]     direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\n  [ComfyUI]                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\n  [ComfyUI]     skeleton = predict_skeleton(\n  [ComfyUI]                ^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n  [ComfyUI]     return func(*args, **kwargs)\n  [ComfyUI]            ^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\n  [ComfyUI]     model, tokenizer = get_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\n  [ComfyUI]     _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\n  [ComfyUI]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\n  [ComfyUI]     from src.model.parse import get_model\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\n  [ComfyUI]     from .unirig_ar import UniRigAR\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\n  [ComfyUI]     from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\n  [ComfyUI]     from .pointcept.models.PTv3Object import get_encoder as get_encoder_ptv3obj\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/__init__.py\", line 1, in <module>\n  [ComfyUI]     from .PTv3Object import PointTransformerV3Object\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/PTv3Object.py\", line 6, in <module>\n  [ComfyUI]     import spconv.pytorch as spconv\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/__init__.py\", line 7, in <module>\n  [ComfyUI]     from spconv.pytorch.core import SparseConvTensor\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/core.py\", line 21, in <module>\n  [ComfyUI]     from spconv.tools import CUDAKernelTimer\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/tools.py\", line 16, in <module>\n  [ComfyUI]     from spconv.cppconstants import CPU_ONLY_BUILD\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/cppconstants.py\", line 15, in <module>\n  [ComfyUI]     import spconv.core_cc as _ext\n  [ComfyUI] ImportError: arg(): could not convert default argument 'workspace: tv::Tensor' in method '<class 'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple'>.run_with_tuned_result' into a Python object (type not registered yet?)\n  [ComfyUI] \n  [ComfyUI] \n  [ComfyUI] Prompt executed in 48.93 seconds\n  Execution error: {'prompt_id': '8941b084-c248-4210-9f28-43fcc07831be', 'node_id': '39', 'node_type': 'UniRigAutoRig', 'executed': ['40', '27'], 'exception_message': 'arg(): could not convert default argument \\'workspace: tv::Tensor\\' in method \\'<class \\'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple\\'>.run_with_tuned_result\\' into a Python object (type not registered yet?)\\n\\nWorker traceback:\\nTraceback (most recent call last):\\n  File \"/tmp/comfyui_pvenv_2c4k1dr4/persistent_worker.py\", line 155, in main\\n    result = method(**inputs)\\n             ^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/auto_rig.py\", line 92, in auto_rig\\n    normalized_mesh, skeleton, texture_preview = skeleton_extractor.extract(\\n                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/skeleton_extraction.py\", line 415, in extract\\n    direct_skeleton_result, norm_params = direct_module.predict_skeleton_from_mesh(\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\\n    return func(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 515, in predict_skeleton_from_mesh\\n    skeleton = predict_skeleton(\\n               ^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\\n    return func(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 321, in predict_skeleton\\n    model, tokenizer = get_skeleton_model(checkpoint_path, device)\\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 273, in get_skeleton_model\\n    _MODEL_CACHE[cache_key] = _load_skeleton_model(checkpoint_path, device)\\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\", line 165, in _load_skeleton_model\\n    from src.model.parse import get_model\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse.py\", line 1, in <module>\\n    from .unirig_ar import UniRigAR\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/unirig_ar.py\", line 16, in <module>\\n    from .parse_encoder import MAP_MESH_ENCODER, get_mesh_encoder\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/parse_encoder.py\", line 7, in <module>\\n    from .pointcept.models.PTv3Object import get_encoder as get_encoder_ptv3obj\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/__init__.py\", line 1, in <module>\\n    from .PTv3Object import PointTransformerV3Object\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/model/pointcept/models/PTv3Object.py\", line 6, in <module>\\n    import spconv.pytorch as spconv\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/__init__.py\", line 7, in <module>\\n    from spconv.pytorch.core import SparseConvTensor\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/pytorch/core.py\", line 21, in <module>\\n    from spconv.tools import CUDAKernelTimer\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/tools.py\", line 16, in <module>\\n    from spconv.cppconstants import CPU_ONLY_BUILD\\n  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/spconv/cppconstants.py\", line 15, in <module>\\n    import spconv.core_cc as _ext\\nImportError: arg(): could not convert default argument \\'workspace: tv::Tensor\\' in method \\'<class \\'spconv.core_cc.csrc.sparse.convops.gemmops.GemmTunerSimple\\'>.run_with_tuned_result\\' into a Python object (type not registered yet?)\\n\\n', 'exception_type': 'comfy_env.workers.base.WorkerError', 'traceback': ['  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\\n    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\\n    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\\n    await process_inputs(input_dict, i)\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\\n    result = f(**inputs)\\n             ^^^^^^^^^^^\\n', '  File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/decorator.py\", line 412, in proxy\\n    result = worker.call_method(\\n             ^^^^^^^^^^^^^^^^^^^\\n', '  File \"/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/comfy_env/workers/venv.py\", line 1014, in call_method\\n    raise WorkerError(\\n'], 'current_inputs': {'skeleton_template': ['mixamo'], 'fbx_name': [''], 'target_face_count': [50000], 'trimesh': ['<trimesh.Trimesh(vertices.shape=(394992, 3), faces.shape=(642547, 3), name=`realistic_male_character.glb`)>'], 'model': [\"{'skeleton_model': {'type': 'skeleton', 'model_id': 'apozz/UniRig-safetensors', 'task_config_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml', 'checkpoint_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors', 'model_config': {'__target__': 'unirig_ar', 'llm': {'pretrained_model_name_or_path': 'facebook/opt-350m', 'n_positions': 3076, 'max_position_embeddings': 3076, 'hidden_size': 1024, 'num_attention_heads': 16, 'num_hidden_layers': 24, 'ffn_dim': 4096, 'word_embed_proj_dim': 1024, 'do_layer_norm_before': True, '_attn_implementation': 'flash_attention_2'}, 'mesh_encoder': {'__target__': 'michelangelo_encoder', 'pretrained_path': None, 'freeze_encoder': False, 'device': 'cpu', 'dtype': 'float32', 'num_latents': 512, 'embed_dim': 64, 'point_feats': 3, 'num_freqs': 8, 'include_pi': False, 'heads': 8, 'width': 512, 'num_encoder_layers': 16, 'use_ln_post': True, 'init_scale': 0.25, 'qkv_bias': False, 'use_checkpoint': False, 'flash': True, 'supervision_type': 'sdf', 'query_method': False, 'token_num': 1024}}, 'tokenizer_config': {'method': 'tokenizer_part', 'num_discrete': 256, 'continuous_range': [-1, 1], 'cls_token_id': {'vroid': 0, 'mixamo': 1, 'articulationxl': 2}, 'parts_token_id': {'body': 0, 'hand': 1}, 'order_config': {'skeleton_path': {'vroid': './configs/skeleton/vroid.yaml', 'mixamo': './configs/skeleton/mixamo.yaml'}}}, 'unirig_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig', 'models_dir': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig', 'cached': True, 'cache_to_gpu': False, 'model_cache_key': None}, 'skinning_model': {'type': 'skinning', 'model_id': 'apozz/UniRig-safetensors', 'task_config_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/configs/task/quick_inference_unirig_skin.yaml', 'checkpoint_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors', 'model_config': {'__target__': 'unirig_skin', 'num_train_vertex': 512, 'num_heads': 16, 'feat_dim': 768, 'grid_size': 0.005, 'mlp_dim': 512, 'num_bone_attn': 8, 'num_mesh_bone_attn': 16, 'bone_embed_dim': 1024, 'voxel_mask': 3.0, 'mesh_encoder': {'__target__': 'ptv3obj', 'pretrained_path': None, 'freeze_encoder': False, 'in_channels': 9, 'cls_mode': False, 'shuffle_orders': True, 'drop_path': 0.0, 'upcast_attention': False, 'upcast_softmax': False, 'enc_depths': [3, 3, 3, 6, 16], 'enc_channels': [32, 64, 128, 256, 384], 'enc_num_head': [2, 4, 8, 16, 24], 'enable_qknorm': True, 'layer_norm': False, 'res_linear': True}, 'global_encoder': {'__target__': 'michelangelo_encoder', 'pretrained_path': None, 'freeze_encoder': False, 'device': 'cpu', 'dtype': 'float32', 'num_latents': 512, 'embed_dim': 64, 'point_feats': 3, 'num_freqs': 8, 'include_pi': False, 'heads': 8, 'width': 512, 'num_encoder_layers': 16, 'use_ln_post': True, 'init_scale': 0.25, 'qkv_bias': False, 'use_checkpoint': False, 'flash': True, 'supervision_type': 'sdf', 'query_method': False, 'token_num': 1024}}, 'unirig_path': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig', 'models_dir': '/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig', 'cached': True, 'cache_to_gpu': False, 'model_cache_key': None}, 'model_id': 'apozz/UniRig-safetensors', 'cache_to_gpu': False}\"]}, 'current_outputs': ['40', '39', '10', '27'], 'timestamp': 1769303598876}"}, {"file": "frame_007.jpg", "time": 66.68509030342102, "log": "Final screenshot"}], "total_time": 51.14}, "rig_human_with_texture_mia_debug": {"frames": [{"file": "frame_000.jpg", "time": 0.0, "log": "Capturing execution frames: rig_human_with_texture_mia_debug.json"}, {"file": "frame_001.jpg", "time": 0.18, "log": "Capturing execution frames: rig_human_with_texture_mia_debug.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI]   Node 49: UniRigCompareSkeletons\n  [ComfyUI]     Inputs: {\"fbx_path_left\": [\"42\", 0], \"fbx_path_right\": [\"51\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 50: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/mixamo.fbx\"}\n  [ComfyUI]   Node 51: PrimitiveString\n  [ComfyUI]     Inputs: {\"value\": \"/home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\"}\n  [ComfyUI] Generated prompt_id: fb321b26-dd6d-4d99-acc9-964590049773\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] !!! Exception during processing !!! Right FBX file not found: /home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\n  [ComfyUI]     output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\n  [ComfyUI]     return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n  [ComfyUI]     await process_inputs(input_dict, i)\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\n  [ComfyUI]     result = f(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/nodes/skeleton_io.py\", line 633, in compare_skeletons\n  [ComfyUI]     raise RuntimeError(f\"Right FBX file not found: {fbx_path_right}\")\n  [ComfyUI] RuntimeError: Right FBX file not found: /home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] \n  [ComfyUI] Prompt executed in 0.01 seconds"}, {"file": "frame_002.jpg", "time": 0.59, "log": "Capturing execution frames: rig_human_with_texture_mia_debug.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI]   Node 49: UniRigCompareSkeletons\n  [ComfyUI]     Inputs: {\"fbx_path_left\": [\"42\", 0], \"fbx_path_right\": [\"51\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 50: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/mixamo.fbx\"}\n  [ComfyUI]   Node 51: PrimitiveString\n  [ComfyUI]     Inputs: {\"value\": \"/home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\"}\n  [ComfyUI] Generated prompt_id: fb321b26-dd6d-4d99-acc9-964590049773\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] !!! Exception during processing !!! Right FBX file not found: /home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\n  [ComfyUI]     output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\n  [ComfyUI]     return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n  [ComfyUI]     await process_inputs(input_dict, i)\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\n  [ComfyUI]     result = f(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/nodes/skeleton_io.py\", line 633, in compare_skeletons\n  [ComfyUI]     raise RuntimeError(f\"Right FBX file not found: {fbx_path_right}\")\n  [ComfyUI] RuntimeError: Right FBX file not found: /home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] \n  [ComfyUI] Prompt executed in 0.01 seconds"}, {"file": "frame_003.jpg", "time": 1.73, "log": "Capturing execution frames: rig_human_with_texture_mia_debug.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI]   Node 49: UniRigCompareSkeletons\n  [ComfyUI]     Inputs: {\"fbx_path_left\": [\"42\", 0], \"fbx_path_right\": [\"51\", 0], \"preview\": \"\"}\n  [ComfyUI]   Node 50: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/mixamo.fbx\"}\n  [ComfyUI]   Node 51: PrimitiveString\n  [ComfyUI]     Inputs: {\"value\": \"/home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\"}\n  [ComfyUI] Generated prompt_id: fb321b26-dd6d-4d99-acc9-964590049773\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] !!! Exception during processing !!! Right FBX file not found: /home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] Traceback (most recent call last):\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\n  [ComfyUI]     output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\n  [ComfyUI]     return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n  [ComfyUI]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n  [ComfyUI]     await process_inputs(input_dict, i)\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\n  [ComfyUI]     result = f(**inputs)\n  [ComfyUI]              ^^^^^^^^^^^\n  [ComfyUI]   File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/nodes/skeleton_io.py\", line 633, in compare_skeletons\n  [ComfyUI]     raise RuntimeError(f\"Right FBX file not found: {fbx_path_right}\")\n  [ComfyUI] RuntimeError: Right FBX file not found: /home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\n  [ComfyUI] \n  [ComfyUI] Prompt executed in 0.01 seconds\n  Execution error: {'prompt_id': '6217613b-7a19-47ac-8f2c-a494e6a57486', 'node_id': '49', 'node_type': 'UniRigCompareSkeletons', 'executed': ['51'], 'exception_message': 'Right FBX file not found: /home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx\\n', 'exception_type': 'RuntimeError', 'traceback': ['  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 518, in execute\\n    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 329, in get_output_data\\n    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\\n    await process_inputs(input_dict, i)\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/execution.py\", line 291, in process_inputs\\n    result = f(**inputs)\\n             ^^^^^^^^^^^\\n', '  File \"/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/nodes/skeleton_io.py\", line 633, in compare_skeletons\\n    raise RuntimeError(f\"Right FBX file not found: {fbx_path_right}\")\\n'], 'current_inputs': {'fbx_path_left': ['/home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/output/rigatoni_mia.fbx'], 'fbx_path_right': ['/home/shadeform/unirig/ComfyUI/input/3d/mixamo.fbx']}, 'current_outputs': ['46', '47', '45', '43', '49', '44', '42', '27', '50', '51', '41'], 'timestamp': 1769303817830}"}, {"file": "frame_004.jpg", "time": 8.94444990158081, "log": "Final screenshot"}], "total_time": 1.84}, "rig_human_with_texture_mia": {"frames": [{"file": "frame_000.jpg", "time": 0.0, "log": "Capturing execution frames: rig_human_with_texture_mia.json"}, {"file": "frame_001.jpg", "time": 0.38, "log": "Capturing execution frames: rig_human_with_texture_mia.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 9 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"42\", 0], \"preview\": \"\"}\n  Queuing workflow for execution...\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI] Generated prompt_id: 724971e3-a5ec-4943-8d1f-3e2f87ed8532\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] triangulating faces"}, {"file": "frame_002.jpg", "time": 4.29, "log": "Capturing execution frames: rig_human_with_texture_mia.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 9 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"42\", 0], \"preview\": \"\"}\n  Queuing workflow for execution...\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI] Generated prompt_id: 724971e3-a5ec-4943-8d1f-3e2f87ed8532\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] triangulating faces\n  [ComfyUI] No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`."}, {"file": "frame_003.jpg", "time": 4.59, "log": "Capturing execution frames: rig_human_with_texture_mia.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 9 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"42\", 0], \"preview\": \"\"}\n  Queuing workflow for execution...\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI] Generated prompt_id: 724971e3-a5ec-4943-8d1f-3e2f87ed8532\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] triangulating faces\n  [ComfyUI] No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`."}, {"file": "frame_004.jpg", "time": 35.07, "log": "Capturing execution frames: rig_human_with_texture_mia.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 9 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"42\", 0], \"preview\": \"\"}\n  Queuing workflow for execution...\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI] Generated prompt_id: 724971e3-a5ec-4943-8d1f-3e2f87ed8532\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] triangulating faces\n  [ComfyUI] No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`."}, {"file": "frame_005.jpg", "time": 138.09, "log": "Capturing execution frames: rig_human_with_texture_mia.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 9 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"42\", 0], \"preview\": \"\"}\n  Queuing workflow for execution...\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI] Generated prompt_id: 724971e3-a5ec-4943-8d1f-3e2f87ed8532\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] triangulating faces\n  [ComfyUI] No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n  [ComfyUI]   For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  [ComfyUI]     warnings.warn(\n  [ComfyUI]   [UniRig] Models directory: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig\n  [ComfyUI]   [UniRigLoadModel] Loading UniRig models...\n  [ComfyUI]   [UniRigLoadModel] GPU caching: disabled\n  [ComfyUI]   [UniRigLoadSkeletonModel] Loading skeleton model: apozz/UniRig-safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] GPU caching: disabled (will offload to CPU)\n  [ComfyUI]   [UniRigLoadSkeletonModel] Downloading/verifying checkpoint...\n  [ComfyUI]   [UniRig] Downloading skeleton.safetensors from apozz/UniRig-safetensors...\n  [ComfyUI]   [UniRig] Downloaded to: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] Checkpoint ready: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] Model configuration cached successfully\n  [ComfyUI]   [UniRigLoadSkeletonModel] Checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Loading skinning model: apozz/UniRig-safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] GPU caching: disabled (will offload to CPU)\n  [ComfyUI]   [UniRigLoadSkinningModel] Downloading/verifying checkpoint...\n  [ComfyUI]   [UniRig] Downloading skin.safetensors from apozz/UniRig-safetensors...\n  [ComfyUI]   [UniRig] Downloaded to: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Checkpoint ready: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Model configuration cached successfully\n  [ComfyUI]   [UniRigLoadSkinningModel] Checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadModel] Both models loaded successfully\n  [ComfyUI]   [UniRigAutoRig] Starting complete rigging pipeline...\n  [ComfyUI]   [UniRigAutoRig] Skeleton template: mixamo\n  [ComfyUI]   [UniRigAutoRig] Step 1/2: Extracting skeleton...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Starting skeleton extraction (cached model only)...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Skeleton template: mixamo\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mixamo requested, using vroid extraction + name remapping\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using pre-loaded cached model\n  [ComfyUI]   [UniRigExtractSkeletonNew] Exporting mesh to /tmp/tmp4f5eddu9/input.glb\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mesh has 394992 vertices, 642547 faces\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mesh exported in 0.35s\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using target face count: 50000\n  [ComfyUI]   [UniRig] Loaded direct preprocessing module from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct_preprocess.py\n  [ComfyUI]   [UniRigExtractSkeletonNew] Step 1: Preprocessing mesh with direct bpy...\n  [ComfyUI]   [Direct Preprocess] Input: /tmp/tmp4f5eddu9/input.glb\n  [ComfyUI]   [Direct Preprocess] Output: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [Direct Preprocess] Target faces: 50000\n  [ComfyUI]   [Direct Preprocess] Loading .glb file...\n  [ComfyUI]   [Direct Preprocess] Import successful\n  [ComfyUI]   [Direct Preprocess] Found 1 mesh(es)\n  [ComfyUI]   [Direct Preprocess] Processing mesh: geometry_0\n  [ComfyUI]   [Direct Preprocess] Triangulating...\n  [ComfyUI]   [Direct Preprocess] Current face count: 642547\n  [ComfyUI]   [Direct Preprocess] Decimating to 50000 faces...\n  [ComfyUI]   [Direct Preprocess] Decimated to 50000 faces\n  [ComfyUI]   [Direct Preprocess] Extracted 71646 vertices, 50000 faces\n  [ComfyUI]   [Direct Preprocess] Calculated vertex normals\n  [ComfyUI]   [Direct Preprocess] Calculated face normals\n  [ComfyUI]   [Direct Preprocess] Extracted UV coordinates: 150000 UVs for 50000 faces\n  [ComfyUI]   [Direct Preprocess] Found texture node: Image Texture\n  [ComfyUI]   [Direct Preprocess] Texture path:\n  [ComfyUI]   [Direct Preprocess] Extracting texture: 1024x1024, 4 channels\n  [ComfyUI]   [Direct Preprocess] Texture encoded: 1331.3 KB base64\n  [ComfyUI]   [Direct Preprocess] Texture extracted successfully: 1024x1024 PNG\n  [ComfyUI]   [Direct Preprocess] Material: tripo_mat_d0bcade7\n  [ComfyUI]   [Direct Preprocess] Saved to: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [Direct Preprocess] Texture data included: 1024x1024 PNG\n  [ComfyUI]   [Direct Preprocess] Done!\n  [ComfyUI]   [UniRigExtractSkeletonNew] [OK] Mesh preprocessed in 16.52s: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [UniRigExtractSkeletonNew] Forcing skeleton template: vroid\n  [ComfyUI]   [UniRig] Loaded direct inference module from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\n  [ComfyUI]   [UniRigExtractSkeletonNew] Step 2: Running skeleton inference...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [MIALoadModel] Loading Make-It-Animatable models...\n  [ComfyUI]   [MIALoadModel] GPU caching: enabled\n  [ComfyUI]   [MIA] Downloading missing models: ['bw.pth', 'bw_normal.pth', 'joints.pth', 'joints_coarse.pth', 'pose.pth']\n  [ComfyUI]   [MIA] Downloading bw.pth...\n  [ComfyUI]   [MIA] Downloading bw_normal.pth...\n  [ComfyUI]   [MIA] Downloading joints.pth...\n  [ComfyUI]   [MIA] Downloading joints_coarse.pth...\n  [ComfyUI]   [MIA] Downloading pose.pth...\n  [ComfyUI]   [MIA] All models downloaded successfully\n  [ComfyUI]   [MIA] Loading models to cpu...\n  [ComfyUI]   [MIA] Loading joints_coarse model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/joints_coarse.pth\n  [ComfyUI]   [MIA] Loading bw model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/bw.pth\n  [ComfyUI]   [MIA] Loading bw_normal model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/bw_normal.pth\n  [ComfyUI]   [MIA] Loading joints model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/joints.pth\n  [ComfyUI]   [MIA] Loading pose model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/pose.pth\n  [ComfyUI]   [MIA] All models loaded successfully\n  [ComfyUI]   [MIALoadModel] Models loaded successfully\n  [ComfyUI]   [MIAAutoRig] Starting Make-It-Animatable rigging pipeline...\n  [ComfyUI]   [MIAAutoRig] Options: no_fingers=False, use_normal=False, reset_to_rest=True\n  [ComfyUI]   [MIA] Starting inference...\n  [ComfyUI]   [MIA] Options: no_fingers=False, use_normal=False, reset_to_rest=True\n  [ComfyUI]   [MIA] Input mesh: 394992 vertices, 642547 faces\n  [ComfyUI]   [MIA] Input mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA]   Material type: PBRMaterial\n  [ComfyUI]   [MIA]   Has baseColorTexture!\n  [ComfyUI]   [MIA] Preparing input...\n  [ComfyUI]   [MIA] After prepare_input: data.mesh has 394992 vertices\n  [ComfyUI]   [MIA]   data.mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA]   Has material: PBRMaterial\n  [ComfyUI]   [MIA] Preprocessing...\n  [ComfyUI]   [MIA] Running model inference...\n  [ComfyUI]   [MIA] Post-processing...\n  [ComfyUI]   [MIA] reset_to_rest=True, data.pose is None: False\n  [ComfyUI]   [MIA] Pose shape: torch.Size([1, 52, 6])\n  [ComfyUI]   [MIA] Saved pose data to /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/temp/mia_pose_debug.npy\n  [ComfyUI]   [MIA] Exporting to FBX...\n  [ComfyUI]   [MIA] Using bpy directly for FBX export...\n  [ComfyUI]   [MIA Export] Mesh to export: 394992 vertices, 642547 faces\n  [ComfyUI]   [MIA Export] Mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA Export]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA Export]   Material type: PBRMaterial\n  [ComfyUI]   [MIA Export]   Has baseColorTexture!\n  [ComfyUI]   [MIA Export] About to export mesh to: /tmp/tmpslb97xmk.glb\n  [ComfyUI]   [MIA Export] Mesh has visual: True\n  [ComfyUI]   [MIA Export] Visual kind: texture\n  [ComfyUI]   [MIA Export] Has UV: shape=(394992, 2)\n  [ComfyUI]   [MIA Export] Material: PBRMaterial\n  [ComfyUI]   [MIA Export]   baseColorTexture: Image\n  [ComfyUI]   [MIA Export] Exported GLB size: 16287072 bytes\n  [ComfyUI]   [MIA Export] Weights: (394992, 52), Joints: (52, 3), Bones: 52\n  [ComfyUI]   FBX version: 7700\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported01:14:56 | INFO: Data are loaded, start creating Blender stuff\n  [ComfyUI]   01:14:56 | INFO: Blender create Mesh node geometry_0\n  [ComfyUI]   01:14:56 | INFO: glTF import finished in 0.62s\n  [ComfyUI]   01:15:52 | INFO: Starting glTF 2.0 export\n  [ComfyUI]   01:15:53 | INFO: Extracting primitive: geometry_0\n  [ComfyUI]   01:15:57 | INFO: Primitives created: 1\n  [ComfyUI]   01:15:57 | WARNING: There are more than 4 joint vertex influences.The 4 with highest weight will be used (and normalized).\n  [ComfyUI]   01:15:59 | INFO: Finished glTF 2.0 export in 6.365877628326416 s\n  [ComfyUI] triangulating faces"}, {"file": "frame_006.jpg", "time": 138.55, "log": "Capturing execution frames: rig_human_with_texture_mia.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 9 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"42\", 0], \"preview\": \"\"}\n  Queuing workflow for execution...\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI] Generated prompt_id: 724971e3-a5ec-4943-8d1f-3e2f87ed8532\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] triangulating faces\n  [ComfyUI] No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n  [ComfyUI]   For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  [ComfyUI]     warnings.warn(\n  [ComfyUI]   [UniRig] Models directory: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig\n  [ComfyUI]   [UniRigLoadModel] Loading UniRig models...\n  [ComfyUI]   [UniRigLoadModel] GPU caching: disabled\n  [ComfyUI]   [UniRigLoadSkeletonModel] Loading skeleton model: apozz/UniRig-safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] GPU caching: disabled (will offload to CPU)\n  [ComfyUI]   [UniRigLoadSkeletonModel] Downloading/verifying checkpoint...\n  [ComfyUI]   [UniRig] Downloading skeleton.safetensors from apozz/UniRig-safetensors...\n  [ComfyUI]   [UniRig] Downloaded to: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] Checkpoint ready: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] Model configuration cached successfully\n  [ComfyUI]   [UniRigLoadSkeletonModel] Checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Loading skinning model: apozz/UniRig-safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] GPU caching: disabled (will offload to CPU)\n  [ComfyUI]   [UniRigLoadSkinningModel] Downloading/verifying checkpoint...\n  [ComfyUI]   [UniRig] Downloading skin.safetensors from apozz/UniRig-safetensors...\n  [ComfyUI]   [UniRig] Downloaded to: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Checkpoint ready: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Model configuration cached successfully\n  [ComfyUI]   [UniRigLoadSkinningModel] Checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadModel] Both models loaded successfully\n  [ComfyUI]   [UniRigAutoRig] Starting complete rigging pipeline...\n  [ComfyUI]   [UniRigAutoRig] Skeleton template: mixamo\n  [ComfyUI]   [UniRigAutoRig] Step 1/2: Extracting skeleton...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Starting skeleton extraction (cached model only)...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Skeleton template: mixamo\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mixamo requested, using vroid extraction + name remapping\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using pre-loaded cached model\n  [ComfyUI]   [UniRigExtractSkeletonNew] Exporting mesh to /tmp/tmp4f5eddu9/input.glb\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mesh has 394992 vertices, 642547 faces\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mesh exported in 0.35s\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using target face count: 50000\n  [ComfyUI]   [UniRig] Loaded direct preprocessing module from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct_preprocess.py\n  [ComfyUI]   [UniRigExtractSkeletonNew] Step 1: Preprocessing mesh with direct bpy...\n  [ComfyUI]   [Direct Preprocess] Input: /tmp/tmp4f5eddu9/input.glb\n  [ComfyUI]   [Direct Preprocess] Output: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [Direct Preprocess] Target faces: 50000\n  [ComfyUI]   [Direct Preprocess] Loading .glb file...\n  [ComfyUI]   [Direct Preprocess] Import successful\n  [ComfyUI]   [Direct Preprocess] Found 1 mesh(es)\n  [ComfyUI]   [Direct Preprocess] Processing mesh: geometry_0\n  [ComfyUI]   [Direct Preprocess] Triangulating...\n  [ComfyUI]   [Direct Preprocess] Current face count: 642547\n  [ComfyUI]   [Direct Preprocess] Decimating to 50000 faces...\n  [ComfyUI]   [Direct Preprocess] Decimated to 50000 faces\n  [ComfyUI]   [Direct Preprocess] Extracted 71646 vertices, 50000 faces\n  [ComfyUI]   [Direct Preprocess] Calculated vertex normals\n  [ComfyUI]   [Direct Preprocess] Calculated face normals\n  [ComfyUI]   [Direct Preprocess] Extracted UV coordinates: 150000 UVs for 50000 faces\n  [ComfyUI]   [Direct Preprocess] Found texture node: Image Texture\n  [ComfyUI]   [Direct Preprocess] Texture path:\n  [ComfyUI]   [Direct Preprocess] Extracting texture: 1024x1024, 4 channels\n  [ComfyUI]   [Direct Preprocess] Texture encoded: 1331.3 KB base64\n  [ComfyUI]   [Direct Preprocess] Texture extracted successfully: 1024x1024 PNG\n  [ComfyUI]   [Direct Preprocess] Material: tripo_mat_d0bcade7\n  [ComfyUI]   [Direct Preprocess] Saved to: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [Direct Preprocess] Texture data included: 1024x1024 PNG\n  [ComfyUI]   [Direct Preprocess] Done!\n  [ComfyUI]   [UniRigExtractSkeletonNew] [OK] Mesh preprocessed in 16.52s: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [UniRigExtractSkeletonNew] Forcing skeleton template: vroid\n  [ComfyUI]   [UniRig] Loaded direct inference module from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\n  [ComfyUI]   [UniRigExtractSkeletonNew] Step 2: Running skeleton inference...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [MIALoadModel] Loading Make-It-Animatable models...\n  [ComfyUI]   [MIALoadModel] GPU caching: enabled\n  [ComfyUI]   [MIA] Downloading missing models: ['bw.pth', 'bw_normal.pth', 'joints.pth', 'joints_coarse.pth', 'pose.pth']\n  [ComfyUI]   [MIA] Downloading bw.pth...\n  [ComfyUI]   [MIA] Downloading bw_normal.pth...\n  [ComfyUI]   [MIA] Downloading joints.pth...\n  [ComfyUI]   [MIA] Downloading joints_coarse.pth...\n  [ComfyUI]   [MIA] Downloading pose.pth...\n  [ComfyUI]   [MIA] All models downloaded successfully\n  [ComfyUI]   [MIA] Loading models to cpu...\n  [ComfyUI]   [MIA] Loading joints_coarse model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/joints_coarse.pth\n  [ComfyUI]   [MIA] Loading bw model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/bw.pth\n  [ComfyUI]   [MIA] Loading bw_normal model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/bw_normal.pth\n  [ComfyUI]   [MIA] Loading joints model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/joints.pth\n  [ComfyUI]   [MIA] Loading pose model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/pose.pth\n  [ComfyUI]   [MIA] All models loaded successfully\n  [ComfyUI]   [MIALoadModel] Models loaded successfully\n  [ComfyUI]   [MIAAutoRig] Starting Make-It-Animatable rigging pipeline...\n  [ComfyUI]   [MIAAutoRig] Options: no_fingers=False, use_normal=False, reset_to_rest=True\n  [ComfyUI]   [MIA] Starting inference...\n  [ComfyUI]   [MIA] Options: no_fingers=False, use_normal=False, reset_to_rest=True\n  [ComfyUI]   [MIA] Input mesh: 394992 vertices, 642547 faces\n  [ComfyUI]   [MIA] Input mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA]   Material type: PBRMaterial\n  [ComfyUI]   [MIA]   Has baseColorTexture!\n  [ComfyUI]   [MIA] Preparing input...\n  [ComfyUI]   [MIA] After prepare_input: data.mesh has 394992 vertices\n  [ComfyUI]   [MIA]   data.mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA]   Has material: PBRMaterial\n  [ComfyUI]   [MIA] Preprocessing...\n  [ComfyUI]   [MIA] Running model inference...\n  [ComfyUI]   [MIA] Post-processing...\n  [ComfyUI]   [MIA] reset_to_rest=True, data.pose is None: False\n  [ComfyUI]   [MIA] Pose shape: torch.Size([1, 52, 6])\n  [ComfyUI]   [MIA] Saved pose data to /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/temp/mia_pose_debug.npy\n  [ComfyUI]   [MIA] Exporting to FBX...\n  [ComfyUI]   [MIA] Using bpy directly for FBX export...\n  [ComfyUI]   [MIA Export] Mesh to export: 394992 vertices, 642547 faces\n  [ComfyUI]   [MIA Export] Mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA Export]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA Export]   Material type: PBRMaterial\n  [ComfyUI]   [MIA Export]   Has baseColorTexture!\n  [ComfyUI]   [MIA Export] About to export mesh to: /tmp/tmpslb97xmk.glb\n  [ComfyUI]   [MIA Export] Mesh has visual: True\n  [ComfyUI]   [MIA Export] Visual kind: texture\n  [ComfyUI]   [MIA Export] Has UV: shape=(394992, 2)\n  [ComfyUI]   [MIA Export] Material: PBRMaterial\n  [ComfyUI]   [MIA Export]   baseColorTexture: Image\n  [ComfyUI]   [MIA Export] Exported GLB size: 16287072 bytes\n  [ComfyUI]   [MIA Export] Weights: (394992, 52), Joints: (52, 3), Bones: 52\n  [ComfyUI]   FBX version: 7700\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported01:14:56 | INFO: Data are loaded, start creating Blender stuff\n  [ComfyUI]   01:14:56 | INFO: Blender create Mesh node geometry_0\n  [ComfyUI]   01:14:56 | INFO: glTF import finished in 0.62s\n  [ComfyUI]   01:15:52 | INFO: Starting glTF 2.0 export\n  [ComfyUI]   01:15:53 | INFO: Extracting primitive: geometry_0\n  [ComfyUI]   01:15:57 | INFO: Primitives created: 1\n  [ComfyUI]   01:15:57 | WARNING: There are more than 4 joint vertex influences.The 4 with highest weight will be used (and normalized).\n  [ComfyUI]   01:15:59 | INFO: Finished glTF 2.0 export in 6.365877628326416 s\n  [ComfyUI] triangulating faces\n  [ComfyUI] Prompt executed in 139.31 seconds"}, {"file": "frame_007.jpg", "time": 149.34, "log": "Capturing execution frames: rig_human_with_texture_mia.json\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 9 nodes\n  [ComfyUI]   Node 10: UniRigPreviewRiggedMesh\n  [ComfyUI]     Inputs: {\"fbx_output_path\": [\"42\", 0], \"preview\": \"\"}\n  Queuing workflow for execution...\n  [ComfyUI]   Node 27: UniRigLoadMesh\n  [ComfyUI]     Inputs: {\"source_folder\": \"input\", \"file_path\": \"3d/realistic_male_character.glb\"}\n  [ComfyUI]   Node 41: MIALoadModel\n  [ComfyUI]     Inputs: {\"cache_to_gpu\": true}\n  [ComfyUI]   Node 42: MIAAutoRig\n  [ComfyUI]     Inputs: {\"fbx_name\": \"rigatoni\", \"no_fingers\": false, \"use_normal\": false, \"reset_to_rest\": true, \"trimesh\": [\"45\", 0], \"model\": [\"41\", 0]}\n  [ComfyUI]   Node 43: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"45\", 0]}\n  [ComfyUI]   Node 44: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"43\", 0]}\n  [ComfyUI]   Node 45: GeomPackTransformMesh\n  [ComfyUI]     Inputs: {\"operation\": \"rotate\", \"rotate_z\": 0, \"rotate_y\": 0, \"rotate_x\": 0, \"trimesh\": [\"27\", 0]}\n  [ComfyUI]   Node 46: UniRigOrientationCheck\n  [ComfyUI]     Inputs: {\"max_height\": 512, \"mesh\": [\"27\", 0]}\n  [ComfyUI]   Node 47: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"46\", 0]}\n  [ComfyUI] Generated prompt_id: 724971e3-a5ec-4943-8d1f-3e2f87ed8532\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] triangulating faces\n  [ComfyUI] No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n  [ComfyUI]   /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/_env_unirig/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n  [ComfyUI]   For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  [ComfyUI]     warnings.warn(\n  [ComfyUI]   [UniRig] Models directory: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig\n  [ComfyUI]   [UniRigLoadModel] Loading UniRig models...\n  [ComfyUI]   [UniRigLoadModel] GPU caching: disabled\n  [ComfyUI]   [UniRigLoadSkeletonModel] Loading skeleton model: apozz/UniRig-safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] GPU caching: disabled (will offload to CPU)\n  [ComfyUI]   [UniRigLoadSkeletonModel] Downloading/verifying checkpoint...\n  [ComfyUI]   [UniRig] Downloading skeleton.safetensors from apozz/UniRig-safetensors...\n  [ComfyUI]   [UniRig] Downloaded to: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] Checkpoint ready: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkeletonModel] Model configuration cached successfully\n  [ComfyUI]   [UniRigLoadSkeletonModel] Checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Loading skinning model: apozz/UniRig-safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] GPU caching: disabled (will offload to CPU)\n  [ComfyUI]   [UniRigLoadSkinningModel] Downloading/verifying checkpoint...\n  [ComfyUI]   [UniRig] Downloading skin.safetensors from apozz/UniRig-safetensors...\n  [ComfyUI]   [UniRig] Downloaded to: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Checkpoint ready: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadSkinningModel] Model configuration cached successfully\n  [ComfyUI]   [UniRigLoadSkinningModel] Checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skin.safetensors\n  [ComfyUI]   [UniRigLoadModel] Both models loaded successfully\n  [ComfyUI]   [UniRigAutoRig] Starting complete rigging pipeline...\n  [ComfyUI]   [UniRigAutoRig] Skeleton template: mixamo\n  [ComfyUI]   [UniRigAutoRig] Step 1/2: Extracting skeleton...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Starting skeleton extraction (cached model only)...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Skeleton template: mixamo\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mixamo requested, using vroid extraction + name remapping\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using pre-loaded cached model\n  [ComfyUI]   [UniRigExtractSkeletonNew] Exporting mesh to /tmp/tmp4f5eddu9/input.glb\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mesh has 394992 vertices, 642547 faces\n  [ComfyUI]   [UniRigExtractSkeletonNew] Mesh exported in 0.35s\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using target face count: 50000\n  [ComfyUI]   [UniRig] Loaded direct preprocessing module from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct_preprocess.py\n  [ComfyUI]   [UniRigExtractSkeletonNew] Step 1: Preprocessing mesh with direct bpy...\n  [ComfyUI]   [Direct Preprocess] Input: /tmp/tmp4f5eddu9/input.glb\n  [ComfyUI]   [Direct Preprocess] Output: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [Direct Preprocess] Target faces: 50000\n  [ComfyUI]   [Direct Preprocess] Loading .glb file...\n  [ComfyUI]   [Direct Preprocess] Import successful\n  [ComfyUI]   [Direct Preprocess] Found 1 mesh(es)\n  [ComfyUI]   [Direct Preprocess] Processing mesh: geometry_0\n  [ComfyUI]   [Direct Preprocess] Triangulating...\n  [ComfyUI]   [Direct Preprocess] Current face count: 642547\n  [ComfyUI]   [Direct Preprocess] Decimating to 50000 faces...\n  [ComfyUI]   [Direct Preprocess] Decimated to 50000 faces\n  [ComfyUI]   [Direct Preprocess] Extracted 71646 vertices, 50000 faces\n  [ComfyUI]   [Direct Preprocess] Calculated vertex normals\n  [ComfyUI]   [Direct Preprocess] Calculated face normals\n  [ComfyUI]   [Direct Preprocess] Extracted UV coordinates: 150000 UVs for 50000 faces\n  [ComfyUI]   [Direct Preprocess] Found texture node: Image Texture\n  [ComfyUI]   [Direct Preprocess] Texture path:\n  [ComfyUI]   [Direct Preprocess] Extracting texture: 1024x1024, 4 channels\n  [ComfyUI]   [Direct Preprocess] Texture encoded: 1331.3 KB base64\n  [ComfyUI]   [Direct Preprocess] Texture extracted successfully: 1024x1024 PNG\n  [ComfyUI]   [Direct Preprocess] Material: tripo_mat_d0bcade7\n  [ComfyUI]   [Direct Preprocess] Saved to: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [Direct Preprocess] Texture data included: 1024x1024 PNG\n  [ComfyUI]   [Direct Preprocess] Done!\n  [ComfyUI]   [UniRigExtractSkeletonNew] [OK] Mesh preprocessed in 16.52s: /tmp/tmp4f5eddu9/input/raw_data.npz\n  [ComfyUI]   [UniRigExtractSkeletonNew] Forcing skeleton template: vroid\n  [ComfyUI]   [UniRig] Loaded direct inference module from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/nodes/lib/unirig/src/inference/direct.py\n  [ComfyUI]   [UniRigExtractSkeletonNew] Step 2: Running skeleton inference...\n  [ComfyUI]   [UniRigExtractSkeletonNew] Using checkpoint: /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/unirig/skeleton.safetensors\n  [ComfyUI]   [MIALoadModel] Loading Make-It-Animatable models...\n  [ComfyUI]   [MIALoadModel] GPU caching: enabled\n  [ComfyUI]   [MIA] Downloading missing models: ['bw.pth', 'bw_normal.pth', 'joints.pth', 'joints_coarse.pth', 'pose.pth']\n  [ComfyUI]   [MIA] Downloading bw.pth...\n  [ComfyUI]   [MIA] Downloading bw_normal.pth...\n  [ComfyUI]   [MIA] Downloading joints.pth...\n  [ComfyUI]   [MIA] Downloading joints_coarse.pth...\n  [ComfyUI]   [MIA] Downloading pose.pth...\n  [ComfyUI]   [MIA] All models downloaded successfully\n  [ComfyUI]   [MIA] Loading models to cpu...\n  [ComfyUI]   [MIA] Loading joints_coarse model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/joints_coarse.pth\n  [ComfyUI]   [MIA] Loading bw model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/bw.pth\n  [ComfyUI]   [MIA] Loading bw_normal model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/bw_normal.pth\n  [ComfyUI]   [MIA] Loading joints model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/joints.pth\n  [ComfyUI]   [MIA] Loading pose model...\n  [ComfyUI]   Loaded model from /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/models/mia/output/best/new/pose.pth\n  [ComfyUI]   [MIA] All models loaded successfully\n  [ComfyUI]   [MIALoadModel] Models loaded successfully\n  [ComfyUI]   [MIAAutoRig] Starting Make-It-Animatable rigging pipeline...\n  [ComfyUI]   [MIAAutoRig] Options: no_fingers=False, use_normal=False, reset_to_rest=True\n  [ComfyUI]   [MIA] Starting inference...\n  [ComfyUI]   [MIA] Options: no_fingers=False, use_normal=False, reset_to_rest=True\n  [ComfyUI]   [MIA] Input mesh: 394992 vertices, 642547 faces\n  [ComfyUI]   [MIA] Input mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA]   Material type: PBRMaterial\n  [ComfyUI]   [MIA]   Has baseColorTexture!\n  [ComfyUI]   [MIA] Preparing input...\n  [ComfyUI]   [MIA] After prepare_input: data.mesh has 394992 vertices\n  [ComfyUI]   [MIA]   data.mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA]   Has material: PBRMaterial\n  [ComfyUI]   [MIA] Preprocessing...\n  [ComfyUI]   [MIA] Running model inference...\n  [ComfyUI]   [MIA] Post-processing...\n  [ComfyUI]   [MIA] reset_to_rest=True, data.pose is None: False\n  [ComfyUI]   [MIA] Pose shape: torch.Size([1, 52, 6])\n  [ComfyUI]   [MIA] Saved pose data to /home/runner/work/ComfyUI-UniRig/ComfyUI-UniRig/.comfy-test-env/ComfyUI/custom_nodes/ComfyUI-UniRig/.comfy-test-env/ComfyUI/temp/mia_pose_debug.npy\n  [ComfyUI]   [MIA] Exporting to FBX...\n  [ComfyUI]   [MIA] Using bpy directly for FBX export...\n  [ComfyUI]   [MIA Export] Mesh to export: 394992 vertices, 642547 faces\n  [ComfyUI]   [MIA Export] Mesh visual type: TextureVisuals\n  [ComfyUI]   [MIA Export]   Has UV coords: (394992, 2)\n  [ComfyUI]   [MIA Export]   Material type: PBRMaterial\n  [ComfyUI]   [MIA Export]   Has baseColorTexture!\n  [ComfyUI]   [MIA Export] About to export mesh to: /tmp/tmpslb97xmk.glb\n  [ComfyUI]   [MIA Export] Mesh has visual: True\n  [ComfyUI]   [MIA Export] Visual kind: texture\n  [ComfyUI]   [MIA Export] Has UV: shape=(394992, 2)\n  [ComfyUI]   [MIA Export] Material: PBRMaterial\n  [ComfyUI]   [MIA Export]   baseColorTexture: Image\n  [ComfyUI]   [MIA Export] Exported GLB size: 16287072 bytes\n  [ComfyUI]   [MIA Export] Weights: (394992, 52), Joints: (52, 3), Bones: 52\n  [ComfyUI]   FBX version: 7700\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported\n  [ComfyUI]   WARNING: User property type 'Short' is not supported01:14:56 | INFO: Data are loaded, start creating Blender stuff\n  [ComfyUI]   01:14:56 | INFO: Blender create Mesh node geometry_0\n  [ComfyUI]   01:14:56 | INFO: glTF import finished in 0.62s\n  [ComfyUI]   01:15:52 | INFO: Starting glTF 2.0 export\n  [ComfyUI]   01:15:53 | INFO: Extracting primitive: geometry_0\n  [ComfyUI]   01:15:57 | INFO: Primitives created: 1\n  [ComfyUI]   01:15:57 | WARNING: There are more than 4 joint vertex influences.The 4 with highest weight will be used (and normalized).\n  [ComfyUI]   01:15:59 | INFO: Finished glTF 2.0 export in 6.365877628326416 s\n  [ComfyUI] triangulating faces\n  [ComfyUI] Prompt executed in 139.31 seconds"}, {"file": "frame_008.jpg", "time": 189.5952558517456, "log": "Final screenshot"}], "total_time": 155.22}};

        // Video player state
        let currentWorkflow = null;
        let playInterval = null;
        let originalLogContent = '';

        // Current frame data for video player
        let currentFrameIndex = 0;
        let currentFrames = [];
        let currentTotalTime = 0;

        function openLightboxByName(name) {
            const w = workflowData[name];
            if (w) openLightbox(w.src, w.title, w.status, w.duration, w.log, w.hardware);
        }

        function openLightbox(src, title, status, duration, logContent, hardware) {
            document.getElementById('lightbox-img').src = src;
            document.getElementById('lightbox-title').textContent = title;
            currentWorkflow = title;
            originalLogContent = logContent;

            const badge = document.getElementById('lightbox-badge');
            badge.textContent = status;
            badge.className = 'lightbox-badge ' + status;

            document.getElementById('lightbox-duration').textContent = duration + 's';
            document.getElementById('lightbox-log').textContent = logContent || '(No log available)';

            // Display hardware info
            const hwEl = document.getElementById('lightbox-hardware');
            if (hardware) {
                const parts = [];
                if (hardware.os) parts.push(hardware.os);
                if (hardware.cpu) parts.push(hardware.cpu);
                if (hardware.gpu) parts.push(hardware.gpu);
                hwEl.textContent = parts.join(' | ');
            } else {
                hwEl.textContent = status === 'skipped' ? '(Did not run on this machine)' : '';
            }

            // Setup video player if video data exists
            const data = videoData[title];
            const videoPlayer = document.getElementById('video-player');

            if (data && data.frames && data.frames.length > 1) {
                currentFrames = data.frames;
                currentTotalTime = data.total_time || data.frames[data.frames.length - 1].time;
                setupVideoSlider(data.frames, currentTotalTime);
                updateVideoFrameByIndex(title, data.frames.length - 1);
                videoPlayer.classList.add('active');
            } else {
                videoPlayer.classList.remove('active');
            }

            document.getElementById('lightbox').classList.add('active');
            history.replaceState(null, '', '#' + encodeURIComponent(title));
        }

        function buildSliderRange(frames, totalTime) {
            // Build noUiSlider range with frames at their time percentages
            const range = { 'min': frames[0].time };
            frames.forEach((frame, idx) => {
                if (idx > 0 && idx < frames.length - 1) {
                    const pct = (frame.time / totalTime * 100).toFixed(1) + '%';
                    range[pct] = frame.time;
                }
            });
            range['max'] = frames[frames.length - 1].time;
            return range;
        }

        function setupVideoSlider(frames, totalTime) {
            const sliderEl = document.getElementById('video-slider');

            // Destroy existing slider if any
            if (sliderEl.noUiSlider) {
                sliderEl.noUiSlider.destroy();
            }

            const range = buildSliderRange(frames, totalTime);

            noUiSlider.create(sliderEl, {
                start: frames[frames.length - 1].time,
                snap: true,
                range: range,
                pips: {
                    mode: 'range',
                    density: 100
                }
            });

            sliderEl.noUiSlider.on('update', function(values) {
                const time = parseFloat(values[0]);
                const frameIdx = frames.findIndex(f => Math.abs(f.time - time) < 0.01);
                if (frameIdx >= 0 && frameIdx !== currentFrameIndex) {
                    currentFrameIndex = frameIdx;
                    showFrame(currentWorkflow, frameIdx);
                }
            });
        }

        function showFrame(workflowName, frameIndex) {
            const data = videoData[workflowName];
            if (!data || !data.frames) return;

            const frame = data.frames[frameIndex];
            const img = document.getElementById('lightbox-img');

            // Use high-quality screenshot for the last frame
            const isLastFrame = frameIndex === data.frames.length - 1;
            if (isLastFrame && workflowData[workflowName] && workflowData[workflowName].src) {
                img.src = workflowData[workflowName].src;
            } else {
                img.src = 'videos/' + workflowName + '/' + frame.file;
            }

            const counter = document.getElementById('video-frame-counter');
            const totalTime = data.total_time || data.frames[data.frames.length - 1].time;
            counter.textContent = frame.time.toFixed(1) + 's / ' + totalTime.toFixed(1) + 's';

            const logEl = document.getElementById('lightbox-log');
            if (frame.log) {
                logEl.textContent = frame.log;
                logEl.scrollTop = logEl.scrollHeight;
            }
        }

        function updateVideoFrameByIndex(workflowName, frameIndex) {
            currentFrameIndex = frameIndex;
            showFrame(workflowName, frameIndex);

            // Update slider position
            const sliderEl = document.getElementById('video-slider');
            if (sliderEl.noUiSlider && currentFrames[frameIndex]) {
                sliderEl.noUiSlider.set(currentFrames[frameIndex].time);
            }
        }

        function toggleVideoPlay() {
            const btn = document.getElementById('video-play-btn');
            if (playInterval) {
                clearInterval(playInterval);
                playInterval = null;
                btn.innerHTML = '&#9654; Play';
            } else {
                btn.innerHTML = '&#9632; Stop';
                playInterval = setInterval(() => {
                    if (!currentFrames.length) return;
                    currentFrameIndex = (currentFrameIndex + 1) % currentFrames.length;
                    updateVideoFrameByIndex(currentWorkflow, currentFrameIndex);
                }, 500);
            }
        }

        function closeLightbox() {
            // Stop video playback
            if (playInterval) {
                clearInterval(playInterval);
                playInterval = null;
                document.getElementById('video-play-btn').innerHTML = '&#9654; Play';
            }
            document.getElementById('lightbox').classList.remove('active');
            // Clear hash
            history.replaceState(null, '', window.location.pathname);
        }

        document.getElementById('lightbox').onclick = (e) => {
            if (e.target.id === 'lightbox') closeLightbox();
        };

        document.onkeydown = (e) => {
            if (e.key === 'Escape') closeLightbox();
        };

        // Handle hash on page load and hash change
        function openFromHash() {
            const hash = decodeURIComponent(window.location.hash.slice(1));
            if (hash && workflowData[hash]) {
                const w = workflowData[hash];
                openLightbox(w.src, w.title, w.status, w.duration, w.log, w.hardware);
            }
        }

        window.addEventListener('hashchange', openFromHash);
        window.addEventListener('load', openFromHash);
    </script>
</body>
</html>